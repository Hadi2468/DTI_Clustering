{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Version control\n",
      "------------------------\n",
      "Numpy\t\t 1.19.4\n",
      "matplotlib\t 3.3.3\n",
      "Pandas\t\t 1.1.4\n"
     ]
    }
   ],
   "source": [
    "## Import some helpful libraries\n",
    "print(\"    Version control\\n------------------------\")\n",
    "import os, fnmatch, random, math, sys, datetime\n",
    "from pathlib import Path\n",
    "import numpy as np;              print(\"Numpy\\t\\t\", np.__version__)\n",
    "import matplotlib as mpl;        print(\"matplotlib\\t\", mpl.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd;             print(\"Pandas\\t\\t {}\".format(pd.__version__))\n",
    "from IPython.display import Image\n",
    "\n",
    "# import nibabel as nib;           print(\"NiBabel\\t\\t {}\".format(nib.__version__))\n",
    "# from nibabel.testing import data_path\n",
    "# import imageio;                  print(\"imageio\\t\\t {}\".format(imageio.__version__))\n",
    "# import h5py;                     print(\"H5py\\t\\t {}\".format(h5py.__version__))\n",
    "# import sklearn;                  print(\"Scikit-learn\\t {}\".format(sklearn.__version__))\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.decomposition import PCA\n",
    "# from scipy.cluster import hierarchy\n",
    "# from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "# import skimage;                  print(\"Scikit-image\\t {}\".format(skimage.__version__))\n",
    "# import tensorflow as tf;         print(\"TensorFlow\\t {}\".format(tf.__version__))\n",
    "# import keras;                    print(\"Keras\\t\\t {}\".format(keras.__version__))\n",
    "# import tensorflow.keras.backend as K\n",
    "# from tensorflow.keras import models, Input, Model\n",
    "# from tensorflow.keras.layers import Dense, Flatten, Reshape, BatchNormalization, Conv3D, MaxPooling3D, UpSampling3D, ZeroPadding3D\n",
    "# from tensorflow.keras.activations import relu, sigmoid\n",
    "# from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "# from tensorflow.keras.initializers import *\n",
    "# from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "# from keras.engine.topology import Layer, InputSpec\n",
    "# from keras.optimizers import SGD\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "# %load_ext tensorboard       \n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuroCognitive Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Loading original Neurocognitive score data\n",
    "\n",
    "# score_df = pd.read_excel('./Data/Neurocognitive_Scores/Scores_original.xlsx')\n",
    "# df = score_df\n",
    "# for p in range (len(df)):\n",
    "#     if df.ID[p][5] == '_': \n",
    "#         df.ID[p] = df.ID[p][0:4] + '00' + df.ID[p][4:]\n",
    "#     elif df.ID[p][6] == '_': \n",
    "#         df.ID[p] = df.ID[p][0:4] + '0' + df.ID[p][4:]\n",
    "# print('\\033[1m There are totally {} records\\n'.format(len(df)))\n",
    "\n",
    "# ## Extract the Baseline_Phase and save\n",
    "# df = df.rename(columns={'Phase Description':'Phase_Description', 'GIA SS':'GIA_SS', 'Proc Spd SS':'Proc_Spd_SS', 'Working Mem SS':'Working_Mem_SS', 'Broad Attn SS':'Broad_Attn_SS'})\n",
    "# df.index = df[df.columns[0]]\n",
    "# df = df.drop(['ID'], axis=1)\n",
    "# df = df.drop(['Date'], axis=1)\n",
    "# df_base = df[(df.Phase_Description == 'Baseline phase') | (df.Phase_Description == 'Baseline Phase')]\n",
    "# df_base.Phase_Description = 'baseline_phase'\n",
    "# print('\\033[1m There are {} records of baseline_phasse\\n'.format(len(df_base)))\n",
    "# df_base.to_csv((r'./Data/Neurocognitive_Scores/baseline.csv'))\n",
    "\n",
    "# ## Extract the 36_months_Phase and save\n",
    "# df_36 = df[(df.Phase_Description == 'Post Dx 36 months')]# | (df.Phase_Description == 'Baseline Phase')]\n",
    "# df_36.Phase_Description = '36_months'\n",
    "# print('\\033[1m There are {} records of 36_months\\n'.format(len(df_36)))\n",
    "# df_36.to_csv((r'./Data/Neurocognitive_Scores/m36.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Generating Scores for Baseline\n",
    "\n",
    "# df_base = pd.read_csv('./Data/Neurocognitive_Scores/baseline.csv')\n",
    "# df_base.index = df_base.ID\n",
    "\n",
    "# ## Baseline_phasse & GIA_Score\n",
    "# df_base_GIA = df_base.GIA_SS\n",
    "# df_base_GIA = df_base_GIA.dropna()   # remove NaN\n",
    "# df_base_GIA = df_base_GIA.astype(int)\n",
    "# # df_base_GIA.to_csv((r'./Data/Neurocognitive_Scores/baseline_GIA.csv'))\n",
    "\n",
    "# ## Baseline_phasse & Process_Spead_Score\n",
    "# df_base_Proc_Spd = df_base.Proc_Spd_SS\n",
    "# df_base_Proc_Spd = df_base_Proc_Spd.dropna()   # remove NaN\n",
    "# df_base_Proc_Spd = df_base_Proc_Spd.astype(int)\n",
    "# # df_base_Proc_Spd.to_csv((r'./Data/Neurocognitive_Scores/baseline_Proc_Spd.csv'))\n",
    "\n",
    "# ## Baseline_phasse & Working_Memory_Score\n",
    "# df_base_Working_Mem = df_base.Working_Mem_SS\n",
    "# df_base_Working_Mem = df_base_Working_Mem.dropna()   # remove NaN\n",
    "# df_base_Working_Mem = df_base_Working_Mem.astype(int)\n",
    "# # df_base_Working_Mem.to_csv((r'./Data/Neurocognitive_Scores/baseline_Working_Mem.csv'))\n",
    "\n",
    "# ## Baseline_phasse & Broad_Attention_Score\n",
    "# df_base_Broad_Attn = df_base.Broad_Attn_SS\n",
    "# df_base_Broad_Attn = df_base_Broad_Attn.dropna()   # remove NaN\n",
    "# df_base_Broad_Attn = df_base_Broad_Attn.astype(int)\n",
    "# # df_base_Broad_Attn.to_csv((r'./Data/Neurocognitive_Scores/baseline_Broad_Attn.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Generating Scores for 36_Months\n",
    "\n",
    "# df_m36 = pd.read_csv('./Data/Neurocognitive_Scores/m36.csv')\n",
    "# df_m36.index = df_m36.ID\n",
    "\n",
    "# ## Month-36 & GIA_Score\n",
    "# df_m36_GIA = df_m36.GIA_SS\n",
    "# df_m36_GIA = df_m36_GIA.dropna()   # remove NaN\n",
    "# df_m36_GIA = df_m36_GIA.astype(int)\n",
    "# # df_m36_GIA.to_csv((r'./Data/Neurocognitive_Scores/m36_GIA.csv'))\n",
    "\n",
    "# ## Month-36 & Process_Spead_Score\n",
    "# df_m36_Proc_Spd = df_m36.Proc_Spd_SS\n",
    "# df_m36_Proc_Spd = df_m36_Proc_Spd.dropna()   # remove NaN\n",
    "# df_m36_Proc_Spd = df_m36_Proc_Spd.astype(int)\n",
    "# # df_m36_Proc_Spd.to_csv((r'./Data/Neurocognitive_Scores/m36_Proc_Spd.csv'))\n",
    "\n",
    "# ## Month-36 & Working_Memory_Score\n",
    "# df_m36_Working_Mem = df_m36.Working_Mem_SS\n",
    "# df_m36_Working_Mem = df_m36_Working_Mem.dropna()   # remove NaN\n",
    "# df_m36_Working_Mem = df_m36_Working_Mem.astype(int)\n",
    "# # df_m36_Working_Mem.to_csv((r'./Data/Neurocognitive_Scores/m36_Working_Mem.csv'))\n",
    "\n",
    "# ## Month-36 & Broad_Attention_Score\n",
    "# df_m36_Broad_Attn = df_m36.Broad_Attn_SS\n",
    "# df_m36_Broad_Attn = df_m36_Broad_Attn.dropna()   # remove NaN\n",
    "# df_m36_Broad_Attn = df_m36_Broad_Attn.astype(int)\n",
    "# # df_m36_Broad_Attn.to_csv((r'./Data/Neurocognitive_Scores/m36_Broad_Attn.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Generating Scores for (36_Months - Baseline_Phase)\n",
    "\n",
    "# ## m36-base & Process_GIA_Score\n",
    "# df_m36_join_base_GIA = pd.merge(df_m36_GIA, df_base_GIA, how='inner', on=['ID'])\n",
    "# df_m36_join_base_GIA['GIA_SS'] = df_m36_join_base_GIA.GIA_SS_x - df_m36_join_base_GIA.GIA_SS_y \n",
    "# df_m36_base_GIA = df_m36_join_base_GIA.drop(['GIA_SS_x', 'GIA_SS_y'], axis=1)\n",
    "# # df_m36_base_GIA.to_csv((r'./Data/Neurocognitive_Scores/m36_base_GIA.csv'), index=False)\n",
    "\n",
    "# ## m36-base & Process_Spead_Score\n",
    "# df_base_Proc_Spd = pd.read_csv('./Data/Neurocognitive_Scores/baseline_Proc_Spd.csv')\n",
    "# df_m36_Proc_Spd = pd.read_csv('./Data/Neurocognitive_Scores/m36_Proc_Spd.csv')\n",
    "# df_m36_join_base_Proc_Spd = pd.merge(df_m36_Proc_Spd, df_base_Proc_Spd, how='inner', on=['ID'])\n",
    "# df_m36_join_base_Proc_Spd['Proc_Spd_SS'] = df_m36_join_base_Proc_Spd.Proc_Spd_SS_x - df_m36_join_base_Proc_Spd.Proc_Spd_SS_y \n",
    "# df_m36_base_Proc_Spd = df_m36_join_base_Proc_Spd.drop(['Proc_Spd_SS_x', 'Proc_Spd_SS_y'], axis=1)\n",
    "# # df_m36_base_Proc_Spd.to_csv((r'./Data/Neurocognitive_Scores/m36_base_Proc_Spd.csv'), index=False)\n",
    "\n",
    "# ## m36-base & Working_Memory_Score\n",
    "# df_base_Working_Mem = pd.read_csv('./Data/Neurocognitive_Scores/baseline_Working_Mem.csv')\n",
    "# df_m36_Working_Mem = pd.read_csv('./Data/Neurocognitive_Scores/m36_Working_Mem.csv')\n",
    "# df_m36_join_base_Working_Mem = pd.merge(df_m36_Working_Mem, df_base_Working_Mem, how='inner', on=['ID'])\n",
    "# df_m36_join_base_Working_Mem['Working_Mem_SS'] = df_m36_join_base_Working_Mem.Working_Mem_SS_x - df_m36_join_base_Working_Mem.Working_Mem_SS_y \n",
    "# df_m36_base_Working_Mem = df_m36_join_base_Working_Mem.drop(['Working_Mem_SS_x', 'Working_Mem_SS_y'], axis=1)\n",
    "# # df_m36_base_Working_Mem.to_csv((r'./Data/Neurocognitive_Scores/m36_base_Working_Mem.csv'), index=False)\n",
    "\n",
    "# ## m36-base & Broad_Attention_Score\n",
    "# df_base_Broad_Attn = pd.read_csv('./Data/Neurocognitive_Scores/baseline_Broad_Attn.csv')\n",
    "# df_m36_Broad_Attn = pd.read_csv('./Data/Neurocognitive_Scores/m36_Broad_Attn.csv')\n",
    "# df_m36_join_base_Broad_Attn = pd.merge(df_m36_Broad_Attn, df_base_Broad_Attn, how='inner', on=['ID'])\n",
    "# df_m36_join_base_Broad_Attn['Broad_Attn_SS'] = df_m36_join_base_Broad_Attn.Broad_Attn_SS_x - df_m36_join_base_Broad_Attn.Broad_Attn_SS_y \n",
    "# df_m36_base_Broad_Attn = df_m36_join_base_Broad_Attn.drop(['Broad_Attn_SS_x', 'Broad_Attn_SS_y'], axis=1)\n",
    "# # df_m36_base_Broad_Attn.to_csv((r'./Data/Neurocognitive_Scores/m36_base_Broad_Attn.csv'), index=False)\n",
    "\n",
    "# ## m36-base for All Scores\n",
    "# df_m36base_all_scores = pd.merge(cluster_m36base_GIA, cluster_m36base_Proc_Spd, how='outer', on=['ID', 'class_e500', 'class_e1500'])\n",
    "# df_m36base_all_scores = pd.merge(df_m36base_all_scores, cluster_m36base_Working_Mem, how='outer', on=['ID', 'class_e500', 'class_e1500'])\n",
    "# df_m36base_all_scores = pd.merge(df_m36base_all_scores, cluster_m36base_Broad_Attn, how='outer', on=['ID', 'class_e500', 'class_e1500'])\n",
    "# df_m36base_all_scores = df_m36base_all_scores.drop(['class_e500', 'class_e1500'], axis=1)\n",
    "# # df_m36base_all_scores.to_csv((r'../Data/data_random_1/Neurocognitive_Joins/df_m36base_all_scores.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>GIA_base</th>\n",
       "      <th>Proc_Spd_base</th>\n",
       "      <th>Working_Mem_base</th>\n",
       "      <th>Broad_Attn_base</th>\n",
       "      <th>GIA_36m</th>\n",
       "      <th>Process_Spd_36m</th>\n",
       "      <th>Working_Mem_36m</th>\n",
       "      <th>Broad_Attn_36m</th>\n",
       "      <th>GIA_diff</th>\n",
       "      <th>Process_Spd_diff</th>\n",
       "      <th>Working_Mem_diff</th>\n",
       "      <th>Broad_Attn_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pat_001_1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pat_002_1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pat_004_1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pat_005_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pat_007_1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Pat_123_1</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Pat_125_1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Pat_131_1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Pat_138_1</td>\n",
       "      <td>107.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Pat_140_1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  GIA_base  Proc_Spd_base  Working_Mem_base  Broad_Attn_base  \\\n",
       "0   Pat_001_1      70.0           51.0              83.0             71.0   \n",
       "1   Pat_002_1      87.0           78.0              92.0             94.0   \n",
       "2   Pat_004_1     122.0          108.0             141.0            130.0   \n",
       "3   Pat_005_1       NaN            NaN              74.0              NaN   \n",
       "4   Pat_007_1      81.0           73.0              93.0             84.0   \n",
       "..        ...       ...            ...               ...              ...   \n",
       "57  Pat_123_1      73.0            NaN              66.0              NaN   \n",
       "58  Pat_125_1      97.0           97.0              87.0             87.0   \n",
       "59  Pat_131_1     110.0           93.0             104.0            105.0   \n",
       "60  Pat_138_1     107.0           92.0             106.0            104.0   \n",
       "61  Pat_140_1     110.0           77.0             102.0             94.0   \n",
       "\n",
       "    GIA_36m  Process_Spd_36m  Working_Mem_36m  Broad_Attn_36m  GIA_diff  \\\n",
       "0      86.0             89.0            105.0            93.0      16.0   \n",
       "1     109.0             86.0             99.0           100.0      22.0   \n",
       "2     127.0             96.0            133.0           121.0       5.0   \n",
       "3      75.0             55.0             91.0            70.0       NaN   \n",
       "4     100.0             96.0            106.0           100.0      19.0   \n",
       "..      ...              ...              ...             ...       ...   \n",
       "57     74.0             48.0             58.0            51.0       1.0   \n",
       "58    107.0            124.0             95.0            97.0      10.0   \n",
       "59    102.0             95.0             95.0            92.0      -8.0   \n",
       "60     87.0             52.0             85.0            79.0     -20.0   \n",
       "61    104.0             96.0             95.0            96.0      -6.0   \n",
       "\n",
       "    Process_Spd_diff  Working_Mem_diff  Broad_Attn_diff  \n",
       "0               38.0              22.0             22.0  \n",
       "1                8.0               7.0              6.0  \n",
       "2              -12.0              -8.0             -9.0  \n",
       "3                NaN              17.0              NaN  \n",
       "4               23.0              13.0             16.0  \n",
       "..               ...               ...              ...  \n",
       "57               NaN              -8.0              NaN  \n",
       "58              27.0               8.0             10.0  \n",
       "59               2.0              -9.0            -13.0  \n",
       "60             -40.0             -21.0            -25.0  \n",
       "61              19.0              -7.0              2.0  \n",
       "\n",
       "[62 rows x 13 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Master Neurocognitive Scores\n",
    "\n",
    "# df_base = pd.read_csv('../Data/data_random_1/Neurocognitive/baseline.csv')\n",
    "# df_base = df_base.drop(['Phase_Description'], axis=1)\n",
    "# df_base = df_base.rename(columns={'GIA_SS': 'GIA_base', 'Proc_Spd_SS': 'Process_Spd_base', \n",
    "#                                   'Working_Mem_SS': 'Working_Mem_base', 'Broad_Attn_SS': 'Broad_Attn_base'})\n",
    "# df_m36 = pd.read_csv('../Data/data_random_1/Neurocognitive/m36.csv')\n",
    "# df_m36 = df_m36.drop(['Phase_Description'], axis=1)\n",
    "# df_m36 = df_m36.rename(columns={'GIA_SS': 'GIA_36m', 'Proc_Spd_SS': 'Process_Spd_36m', \n",
    "#                                 'Working_Mem_SS': 'Working_Mem_36m', 'Broad_Attn_SS': 'Broad_Attn_36m'})\n",
    "# df_m36base_all_scores = pd.read_csv('../Data/data_random_1/Neurocognitive_Joins/df_m36base_all_scores.csv')\n",
    "# df_m36base_all_scores = df_m36base_all_scores.rename(columns={'GIA_SS': 'GIA_diff', 'Proc_Spd_SS': 'Process_Spd_diff', \n",
    "#                                                               'Working_Mem_SS': 'Working_Mem_diff', 'Broad_Attn_SS': 'Broad_Attn_diff'})\n",
    "# master_score = pd.merge(df_base, df_m36, how='inner', on=['ID'])\n",
    "# master_score = pd.merge(master_score, df_m36base_all_scores, how='inner', on=['ID'])\n",
    "# master_score.to_csv('../Data/data_random_1/Neurocognitive_Joins/master_score.csv', index=False)\n",
    "\n",
    "master_score = pd.read_csv(r'../Data/data_random_1/Neurocognitive_Joins/master_score.csv')\n",
    "master_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Joining of Cluster with Baseline\n",
    "\n",
    "# ## Cluster--*--GIA for base\n",
    "# df = pd.merge(df_clusters, df_base_GIA, how='inner', on=['ID'])\n",
    "# df.index = df[df.columns[0]]\n",
    "# df_cluster_join_base_GIA = df.drop(['ID', 'same_clusters'], axis=1)\n",
    "# # df_cluster_join_base_GIA.to_csv((r'../Data/data_random_1/Neurocognitive_Joins/cluster_base_GIA.csv'))\n",
    "\n",
    "# ## Cluster--*--ProcSpd for base\n",
    "# df = pd.merge(df_clusters, df_base_ProcSpd, how='inner', on=['ID'])\n",
    "# df.index = df[df.columns[0]]\n",
    "# df_cluster_join_base_ProcSpd = df.drop(['ID', 'same_clusters'], axis=1)\n",
    "# # df_cluster_join_base_ProcSpd.to_csv((r'../Data/data_random_1/Neurocognitive_Joins/cluster_base_Proc_Spd.csv'))\n",
    "\n",
    "# ## Cluster--*--WorkingMem for base\n",
    "# df = pd.merge(df_clusters, df_base_WorkingMem, how='inner', on=['ID'])\n",
    "# df.index = df[df.columns[0]]\n",
    "# df_cluster_join_base_WorkingMem = df.drop(['ID', 'same_clusters'], axis=1)\n",
    "# # df_cluster_join_base_WorkingMem.to_csv((r'../Data/data_random_1/Neurocognitive_Joins/cluster_base_Working_Mem.csv'))\n",
    "\n",
    "# ## Cluster--*--BroadAttn for base\n",
    "# df = pd.merge(df_clusters, df_base_BroadAttn, how='inner', on=['ID'])\n",
    "# df.index = df[df.columns[0]]\n",
    "# df_cluster_join_base_BroadAttn = df.drop(['ID', 'same_clusters'], axis=1)\n",
    "# # df_cluster_join_base_BroadAttn.to_csv((r'../Data/data_random_1/Neurocognitive_Joins/cluster_base_Broad_Attn.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Joining of Cluster with (36month - baseline)\n",
    "\n",
    "# ## Cluster--*--GIA for m36-base\n",
    "# df = pd.merge(df_clusters, df_m36_base_GIA, how='inner', on=['ID'])\n",
    "# df.index = df[df.columns[0]]\n",
    "# df_cluster_join_m36base_GIA = df.drop(['ID', 'same_clusters'], axis=1)\n",
    "# # df_cluster_join_m36base_GIA.to_csv((r'../Data/data_random_1/Neurocognitive_Joins/cluster_m36base_GIA.csv'))\n",
    "\n",
    "# ## Cluster--*--ProcSpd for m36-base\n",
    "# df = pd.merge(df_clusters, df_m36_base_ProcSpd, how='inner', on=['ID'])\n",
    "# df.index = df[df.columns[0]]\n",
    "# df_cluster_join_m36base_ProcSpd = df.drop(['ID', 'same_clusters'], axis=1)\n",
    "# # df_cluster_join_m36base_ProcSpd.to_csv((r'../Data/data_random_1/Neurocognitive_Joins/cluster_m36base_Proc_Spd.csv'))\n",
    "\n",
    "# ## Cluster--*--WorkingMem for m36-base\n",
    "# df = pd.merge(df_clusters, df_m36_base_WorkingMem, how='inner', on=['ID'])\n",
    "# df.index = df[df.columns[0]]\n",
    "# df_cluster_join_m36base_WorkingMem = df.drop(['ID', 'same_clusters'], axis=1)\n",
    "# # df_cluster_join_m36base_WorkingMem.to_csv((r'../Data/data_random_1/Neurocognitive_Joins/cluster_m36base_Working_Mem.csv'))\n",
    "\n",
    "# ## Cluster--*--BroadAttn for m36-base\n",
    "# df = pd.merge(df_clusters, df_m36_base_BroadAttn, how='inner', on=['ID'])\n",
    "# df.index = df[df.columns[0]]\n",
    "# df_cluster_join_m36base_BroadAttn = df.drop(['ID', 'same_clusters'], axis=1)\n",
    "# # df_cluster_join_m36base_BroadAttn.to_csv((r'../Data/data_random_1/Neurocognitive_Joins/cluster_m36base_Broad_Attn.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Joining of All scores with LF \n",
    "\n",
    "# ## Joining All Scores for Baseline-Phase\n",
    "# df_base_all_scores = pd.merge(df_clusters, df_base, how='inner', on=['ID'])\n",
    "# df_base_all_scores = df_base_all_scores.drop(['same_clusters', 'Phase_Description'], axis=1)\n",
    "# # df_base_all_scores.to_csv((r'../Data/data_random_1/Neurocognitive_Joins/df_base_all_scores.csv'))\n",
    "\n",
    "# ## Joining All Scores for 36m-base\n",
    "# df_m36_all_scores = pd.merge(df_clusters, df_m36, how='inner', on=['ID'])\n",
    "# df_m36_all_scores = df_m36_all_scores.drop(['same_clusters', 'Phase_Description'], axis=1)\n",
    "# # df_m36_all_scores.to_csv((r'../Data/data_random_1/Neurocognitive_Joins/df_m36_all_scores.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9635c17982b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# df_m36_all_scores  = pd.read_csv('../Data/data_random_1/Neurocognitive_Joins/df_m36_all_scores.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m print('\\033[1m Among {} records of Baseline-Phase,'.format(len(df_base)),\n\u001b[0m\u001b[1;32m     15\u001b[0m       'there are {} common records for GIA Score'.format(len(df_cluster_join_base_GIA)))\n\u001b[1;32m     16\u001b[0m print('\\033[1m Among {} records of Baseline-Phase,'.format(len(df_base)),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_base' is not defined"
     ]
    }
   ],
   "source": [
    "df_cluster_join_base_GIA         = pd.read_csv('../Data/data_random_1/Neurocognitive_Joins/cluster_base_GIA.csv')\n",
    "df_cluster_join_base_Proc_Spd    = pd.read_csv('../Data/data_random_1/Neurocognitive_Joins/cluster_base_Proc_Spd.csv')\n",
    "df_cluster_join_base_Working_Mem = pd.read_csv('../Data/data_random_1/Neurocognitive_Joins/cluster_base_Working_Mem.csv')\n",
    "df_cluster_join_base_Broad_Attn  = pd.read_csv('../Data/data_random_1/Neurocognitive_Joins/cluster_base_Broad_Attn.csv')\n",
    "\n",
    "df_cluster_join_m36base_GIA         = pd.read_csv('../Data/data_random_1/Neurocognitive_Joins/cluster_m36base_GIA.csv')\n",
    "df_cluster_join_m36base_Proc_Spd    = pd.read_csv('../Data/data_random_1/Neurocognitive_Joins/cluster_m36base_Proc_Spd.csv')\n",
    "df_cluster_join_m36base_Working_Mem = pd.read_csv('../Data/data_random_1/Neurocognitive_Joins/cluster_m36base_Working_Mem.csv')\n",
    "df_cluster_join_m36base_Broad_Attn  = pd.read_csv('../Data/data_random_1/Neurocognitive_Joins/cluster_m36base_Broad_Attn.csv')\n",
    "\n",
    "# df_base_all_scores  = pd.read_csv('../Data/data_random_1/Neurocognitive_Joins/df_base_all_scores.csv')\n",
    "# df_m36_all_scores  = pd.read_csv('../Data/data_random_1/Neurocognitive_Joins/df_m36_all_scores.csv')\n",
    "\n",
    "print('\\033[1m Among {} records of Baseline-Phase,'.format(len(df_base)),\n",
    "      'there are {} common records for GIA Score'.format(len(df_cluster_join_base_GIA)))\n",
    "print('\\033[1m Among {} records of Baseline-Phase,'.format(len(df_base)),\n",
    "      'there are {} common records for Process Speed Score'.format(len(df_cluster_join_base_Proc_Spd)))\n",
    "print('\\033[1m Among {} records of Baseline-Phase,'.format(len(df_base)),\n",
    "      'there are {} common records for Working Memory Score'.format(len(df_cluster_join_base_Working_Mem)))\n",
    "print('\\033[1m Among {} records of Baseline-Phase,'.format(len(df_base)),\n",
    "      'there are {} common records for Broad Attention Score\\n'.format(len(df_cluster_join_base_Broad_Attn)))\n",
    "\n",
    "print('\\033[1m Among {} records of Month-36,'.format(len(df_m36)) , 'and {} records of Baseline-Phase,'.format(len(df_base)),\n",
    "      'there are {} common records for GIA Score'.format(len(df_cluster_join_m36base_GIA)))\n",
    "print('\\033[1m Among {} records of Month-36,'.format(len(df_m36)) , 'and {} records of Baseline-Phase,'.format(len(df_base)),\n",
    "      'there are {} common records for Process Speed Score'.format(len(df_cluster_join_m36base_Proc_Spd)))\n",
    "print('\\033[1m Among {} records of Month-36,'.format(len(df_m36)) , 'and {} records of Baseline-Phase,'.format(len(df_base)),\n",
    "      'there are {} common records for Working Memory Score'.format(len(df_cluster_join_m36base_Working_Mem)))\n",
    "print('\\033[1m Among {} records of Month-36,'.format(len(df_m36)) , 'and {} records of Baseline-Phase,'.format(len(df_base)),\n",
    "      'there are {} common records for Broad Attention Score\\n'.format(len(df_cluster_join_m36base_Broad_Attn)))\n",
    "\n",
    "print('\\033[1m There are totally {} common records for all scores in the Baseline'.format(len(df_base_all_scores)))\n",
    "print('\\033[1m There are totally {} common records for all scores in (36months-baseline)'.format(len(df_m36_all_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining of LF_500 with Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## LF_500 for Base scores\n",
    "# LF_e500_base_GIA = pd.merge(df_cluster_join_base_GIA, LF_500, how='inner', on=['ID'])\n",
    "# LF_e500_base_GIA.index = LF_e500_base_GIA.ID\n",
    "# LF_e500_base_GIA = LF_e500_base_GIA.drop(['ID', 'class_e1500'], axis=1)\n",
    "# # LF_e500_base_GIA.to_csv(r'../Data/data_random_1/LF_Joins/LF_e500_base_GIA.csv')\n",
    "\n",
    "# LF_e500_base_Proc_Spd = pd.merge(df_cluster_join_base_Proc_Spd, LF_500, how='inner', on=['ID'])\n",
    "# LF_e500_base_Proc_Spd.index = LF_e500_base_Proc_Spd.ID\n",
    "# LF_e500_base_Proc_Spd = LF_e500_base_Proc_Spd.drop(['ID', 'class_e1500'], axis=1)\n",
    "# # LF_e500_base_Proc_Spd.to_csv(r'../Data/data_random_1/LF_Joins/LF_e500_base_Proc_Spd.csv')\n",
    "\n",
    "# LF_e500_base_Working_Mem = pd.merge(df_cluster_join_base_Working_Mem, LF_500, how='inner', on=['ID'])\n",
    "# LF_e500_base_Working_Mem.index = LF_e500_base_Working_Mem.ID\n",
    "# LF_e500_base_Working_Mem = LF_e500_base_Working_Mem.drop(['ID', 'class_e1500'], axis=1)\n",
    "# # LF_e500_base_Working_Mem.to_csv(r'../Data/data_random_1/LF_Joins/LF_e500_base_Working_Mem.csv')\n",
    "\n",
    "# LF_e500_base_Broad_Attn = pd.merge(df_cluster_join_base_Broad_Attn, LF_500, how='inner', on=['ID'])\n",
    "# LF_e500_base_Broad_Attn.index = LF_e500_base_Broad_Attn.ID\n",
    "# LF_e500_base_Broad_Attn = LF_e500_base_Broad_Attn.drop(['ID', 'class_e1500'], axis=1)\n",
    "# # LF_e500_base_Broad_Attn.to_csv(r'../Data/data_random_1/LF_Joins/LF_e500_base_Broad_Attn.csv')\n",
    "\n",
    "# ##---------------------------------------------------------------------------------\n",
    "# ## LF_500 for (Month36-Base) scores\n",
    "# LF_e500_m36base_GIA = pd.merge(df_cluster_join_m36base_GIA, LF_500, how='inner', on=['ID'])\n",
    "# LF_e500_m36base_GIA.index = LF_e500_m36base_GIA.ID\n",
    "# LF_e500_m36base_GIA = LF_e500_m36base_GIA.drop(['ID', 'class_e1500'], axis=1)\n",
    "# # LF_e500_m36base_GIA.to_csv(r'../Data/data_random_1/LF_Joins/LF_e500_m36base_GIA.csv')\n",
    "\n",
    "# LF_e500_m36base_Proc_Spd = pd.merge(df_cluster_join_m36base_Proc_Spd, LF_500, how='inner', on=['ID'])\n",
    "# LF_e500_m36base_Proc_Spd.index = LF_e500_m36base_Proc_Spd.ID\n",
    "# LF_e500_m36base_Proc_Spd = LF_e500_m36base_Proc_Spd.drop(['ID', 'class_e1500'], axis=1)\n",
    "# # LF_e500_m36base_Proc_Spd.to_csv(r'../Data/data_random_1/LF_Joins/LF_e500_m36base_Proc_Spd.csv')\n",
    "\n",
    "# LF_e500_m36base_Working_Mem = pd.merge(df_cluster_join_m36base_Working_Mem, LF_500, how='inner', on=['ID'])\n",
    "# LF_e500_m36base_Working_Mem.index = LF_e500_m36base_Working_Mem.ID\n",
    "# LF_e500_m36base_Working_Mem = LF_e500_m36base_Working_Mem.drop(['ID', 'class_e1500'], axis=1)\n",
    "# # LF_e500_m36base_Working_Mem.to_csv(r'../Data/data_random_1/LF_Joins/LF_e500_m36base_Working_Mem.csv')\n",
    "\n",
    "# LF_e500_m36base_Broad_Attn = pd.merge(df_cluster_join_m36base_Broad_Attn, LF_500, how='inner', on=['ID'])\n",
    "# LF_e500_m36base_Broad_Attn.index = LF_e500_m36base_Broad_Attn.ID\n",
    "# LF_e500_m36base_Broad_Attn = LF_e500_m36base_Broad_Attn.drop(['ID', 'class_e1500'], axis=1)\n",
    "# # LF_e500_m36base_Broad_Attn.to_csv(r'../Data/data_random_1/LF_Joins/LF_e500_m36base_Broad_Attn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LF_500 for Base scores\n",
    "LF_e500_base_GIA         = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e500_base_GIA.csv')\n",
    "LF_e500_base_Proc_Spd    = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e500_base_Proc_Spd.csv')\n",
    "LF_e500_base_Working_Mem = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e500_base_Working_Mem.csv')\n",
    "LF_e500_base_Broad_Attn  = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e500_base_Broad_Attn.csv')\n",
    "\n",
    "## LF_500 for (Month36-Base) scores\n",
    "LF_e500_m36base_GIA         = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e500_m36base_GIA.csv')\n",
    "LF_e500_m36base_Proc_Spd    = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e500_m36base_Proc_Spd.csv')\n",
    "LF_e500_m36base_Working_Mem = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e500_m36base_Working_Mem.csv')\n",
    "LF_e500_m36base_Broad_Attn  = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e500_m36base_Broad_Attn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining of LF_1500 with Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## LF_1500 for Base scores\n",
    "# LF_e1500_base_GIA = pd.merge(df_cluster_join_base_GIA, LF_1500, how='inner', on=['ID'])\n",
    "# LF_e1500_base_GIA.index = LF_e1500_base_GIA.ID\n",
    "# LF_e1500_base_GIA = LF_e1500_base_GIA.drop(['ID', 'class_e500'], axis=1)\n",
    "# # LF_e1500_base_GIA.to_csv(r'../Data/data_random_1/LF_Joins/LF_e1500_base_GIA.csv')\n",
    "\n",
    "# LF_e1500_base_Proc_Spd = pd.merge(df_cluster_join_base_Proc_Spd, LF_1500, how='inner', on=['ID'])\n",
    "# LF_e1500_base_Proc_Spd.index = LF_e1500_base_Proc_Spd.ID\n",
    "# LF_e1500_base_Proc_Spd = LF_e1500_base_Proc_Spd.drop(['ID', 'class_e500'], axis=1)\n",
    "# # LF_e1500_base_Proc_Spd.to_csv(r'../Data/data_random_1/LF_Joins/LF_e1500_base_Proc_Spd.csv')\n",
    "\n",
    "# LF_e1500_base_Working_Mem = pd.merge(df_cluster_join_base_Working_Mem, LF_1500, how='inner', on=['ID'])\n",
    "# LF_e1500_base_Working_Mem.index = LF_e1500_base_Working_Mem.ID\n",
    "# LF_e1500_base_Working_Mem = LF_e1500_base_Working_Mem.drop(['ID', 'class_e500'], axis=1)\n",
    "# # LF_e1500_base_Working_Mem.to_csv(r'../Data/data_random_1/LF_Joins/LF_e1500_base_Working_Mem.csv')\n",
    "\n",
    "# LF_e1500_base_Broad_Attn = pd.merge(df_cluster_join_base_Broad_Attn, LF_1500, how='inner', on=['ID'])\n",
    "# LF_e1500_base_Broad_Attn.index = LF_e1500_base_Broad_Attn.ID\n",
    "# LF_e1500_base_Broad_Attn = LF_e1500_base_Broad_Attn.drop(['ID', 'class_e500'], axis=1)\n",
    "# # LF_e1500_base_Broad_Attn.to_csv(r'../Data/data_random_1/LF_Joins/LF_e1500_base_Broad_Attn.csv')\n",
    "\n",
    "# # ##---------------------------------------------------------------------------------\n",
    "# # ## LF_1500 for (Month36-Base) scores\n",
    "# LF_e1500_m36base_GIA = pd.merge(df_cluster_join_m36base_GIA, LF_1500, how='inner', on=['ID'])\n",
    "# LF_e1500_m36base_GIA.index = LF_e1500_m36base_GIA.ID\n",
    "# LF_e1500_m36base_GIA = LF_e1500_m36base_GIA.drop(['ID', 'class_e500'], axis=1)\n",
    "# # LF_e1500_m36base_GIA.to_csv(r'../Data/data_random_1/LF_Joins/LF_e1500_m36base_GIA.csv')\n",
    "\n",
    "# LF_e1500_m36base_Proc_Spd = pd.merge(df_cluster_join_m36base_Proc_Spd, LF_1500, how='inner', on=['ID'])\n",
    "# LF_e1500_m36base_Proc_Spd.index = LF_e1500_m36base_Proc_Spd.ID\n",
    "# LF_e1500_m36base_Proc_Spd = LF_e1500_m36base_Proc_Spd.drop(['ID', 'class_e500'], axis=1)\n",
    "# # LF_e1500_m36base_Proc_Spd.to_csv(r'../Data/data_random_1/LF_Joins/LF_e1500_m36base_Proc_Spd.csv')\n",
    "\n",
    "# LF_e1500_m36base_Working_Mem = pd.merge(df_cluster_join_m36base_Working_Mem, LF_1500, how='inner', on=['ID'])\n",
    "# LF_e1500_m36base_Working_Mem.index = LF_e1500_m36base_Working_Mem.ID\n",
    "# LF_e1500_m36base_Working_Mem = LF_e1500_m36base_Working_Mem.drop(['ID', 'class_e500'], axis=1)\n",
    "# # LF_e1500_m36base_Working_Mem.to_csv(r'../Data/data_random_1/LF_Joins/LF_e1500_m36base_Working_Mem.csv')\n",
    "\n",
    "# LF_e1500_m36base_Broad_Attn = pd.merge(df_cluster_join_m36base_Broad_Attn, LF_1500, how='inner', on=['ID'])\n",
    "# LF_e1500_m36base_Broad_Attn.index = LF_e1500_m36base_Broad_Attn.ID\n",
    "# LF_e1500_m36base_Broad_Attn = LF_e1500_m36base_Broad_Attn.drop(['ID', 'class_e500'], axis=1)\n",
    "# # LF_e1500_m36base_Broad_Attn.to_csv(r'../Data/data_random_1/LF_Joins/LF_e1500_m36base_Broad_Attn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LF_500 for Base scores\n",
    "LF_e1500_base_GIA         = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e1500_base_GIA.csv')\n",
    "LF_e1500_base_Proc_Spd    = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e1500_base_Proc_Spd.csv')\n",
    "LF_e1500_base_Working_Mem = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e1500_base_Working_Mem.csv')\n",
    "LF_e1500_base_Broad_Attn  = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e1500_base_Broad_Attn.csv')\n",
    "\n",
    "## LF_500 for (Month36-Base) scores\n",
    "LF_e1500_m36base_GIA         = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e1500_m36base_GIA.csv')\n",
    "LF_e1500_m36base_Proc_Spd    = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e1500_m36base_Proc_Spd.csv')\n",
    "LF_e1500_m36base_Working_Mem = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e1500_m36base_Working_Mem.csv')\n",
    "LF_e1500_m36base_Broad_Attn  = pd.read_csv('../Data/data_random_1/LF_Joins/LF_e1500_m36base_Broad_Attn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot features\n",
    "\n",
    "bp = dict(linestyle='-', linewidth=2, color='dodgerblue')\n",
    "mp = dict(linestyle='-', linewidth=2, color='r')\n",
    "wp = dict(linestyle='-', linewidth=2, color='dodgerblue')\n",
    "cp = dict(linestyle='-', linewidth=2, color='dodgerblue')\n",
    "fp = dict(markeredgewidth=2, markersize=10, markeredgecolor='dodgerblue')\n",
    "mnp = dict(marker='o', markerfacecolor='lime', markeredgecolor='k', markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot: Baseline_GIA\n",
    "\n",
    "## e500\n",
    "boxplot = df_cluster_join_base_GIA.boxplot(column=['GIA_SS'], by=['class_e500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"Baseline Phase\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e500)\", fontsize=15)\n",
    "p.set_ylabel(\"GIA score\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "## e1500\n",
    "boxplot = df_cluster_join_base_GIA.boxplot(column=['GIA_SS'], by=['class_e1500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"Baseline Phase\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e1500)\", fontsize=15)\n",
    "p.set_ylabel(\"GIA score\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot: Baseline_ProcSpd\n",
    "\n",
    "## e500\n",
    "boxplot = df_cluster_join_base_Proc_Spd.boxplot(column=['Proc_Spd_SS'], by=['class_e500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"Baseline Phase\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e500)\", fontsize=15)\n",
    "p.set_ylabel(\"Process Speed score\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "## e1500\n",
    "boxplot = df_cluster_join_base_Proc_Spd.boxplot(column=['Proc_Spd_SS'], by=['class_e1500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"Baseline Phase\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e1500)\", fontsize=15)\n",
    "p.set_ylabel(\"Process Speed score\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot: Baseline_WorkingMem\n",
    "\n",
    "## e500\n",
    "boxplot = df_cluster_join_base_Working_Mem.boxplot(column=['Working_Mem_SS'], by=['class_e500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"Baseline Phase\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e500)\", fontsize=15)\n",
    "p.set_ylabel(\"Working Memory score\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "## e1500\n",
    "boxplot = df_cluster_join_base_Working_Mem.boxplot(column=['Working_Mem_SS'], by=['class_e1500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"Baseline Phase\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e1500)\", fontsize=15)\n",
    "p.set_ylabel(\"Working Memory score\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot: Baseline_BroadAttn\n",
    "\n",
    "## e500\n",
    "boxplot = df_cluster_join_base_Broad_Attn.boxplot(column=['Broad_Attn_SS'], by=['class_e500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"Baseline Phase\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e500)\", fontsize=15)\n",
    "p.set_ylabel(\"Broad Attention score\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "## e1500\n",
    "boxplot = df_cluster_join_base_Broad_Attn.boxplot(column=['Broad_Attn_SS'], by=['class_e1500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"Baseline Phase\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e1500)\", fontsize=15)\n",
    "p.set_ylabel(\"Broad Attention score\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot features\n",
    "\n",
    "bp = dict(linestyle='-', linewidth=2, color='blueviolet')\n",
    "mp = dict(linestyle='-', linewidth=2, color='r')\n",
    "wp = dict(linestyle='-', linewidth=2, color='blueviolet')\n",
    "cp = dict(linestyle='-', linewidth=2, color='blueviolet')\n",
    "fp = dict(markeredgewidth=2, markersize=10, markeredgecolor='blueviolet')\n",
    "mnp = dict(marker='o', markerfacecolor='lime', markeredgecolor='k', markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot: (36months - Baseline)_GIA\n",
    "\n",
    "## e500\n",
    "boxplot = df_cluster_join_m36base_GIA.boxplot(column=['GIA_SS'], by=['class_e500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"(36months - Baseline)\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e500)\", fontsize=15)\n",
    "p.set_ylabel(\"GIA score\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "## e1500\n",
    "boxplot = df_cluster_join_m36base_GIA.boxplot(column=['GIA_SS'], by=['class_e1500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"(36months - Baseline)\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e1500)\", fontsize=15)\n",
    "p.set_ylabel(\"GIA score\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot: (36months - Baseline)_ProcSpd\n",
    "\n",
    "## e500\n",
    "boxplot = df_cluster_join_m36base_Proc_Spd.boxplot(column=['Proc_Spd_SS'], by=['class_e500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"(36months - Baseline)\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e500)\", fontsize=15)\n",
    "p.set_ylabel(\"Process Speed score\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "## e1500\n",
    "boxplot = df_cluster_join_m36base_Proc_Spd.boxplot(column=['Proc_Spd_SS'], by=['class_e1500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"(36months - Baseline)\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e1500)\", fontsize=15)\n",
    "p.set_ylabel(\"Process Speed score\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot: (36months - Baseline)_WorkingMem\n",
    "\n",
    "## e500\n",
    "boxplot = df_cluster_join_m36base_Working_Mem.boxplot(column=['Working_Mem_SS'], by=['class_e500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"(36months - Baseline)\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e500)\", fontsize=15)\n",
    "p.set_ylabel(\"Working Memory score\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "## e1500\n",
    "boxplot = df_cluster_join_m36base_Working_Mem.boxplot(column=['Working_Mem_SS'], by=['class_e1500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"(36months - Baseline)\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e1500)\", fontsize=15)\n",
    "p.set_ylabel(\"Working Memory score\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot: (36months - Baseline)_BroadAttn\n",
    "\n",
    "## e500\n",
    "boxplot = df_cluster_join_m36base_Broad_Attn.boxplot(column=['Broad_Attn_SS'], by=['class_e500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"(36months - Baseline)\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e500)\", fontsize=15)\n",
    "p.set_ylabel(\"Broad Attention score\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "## e1500\n",
    "boxplot = df_cluster_join_m36base_Broad_Attn.boxplot(column=['Broad_Attn_SS'], by=['class_e1500'], showfliers=True, showmeans=True, meanprops=mnp,\n",
    "        widths = 0.7, patch_artist=False, grid=False, fontsize=15, boxprops=bp, medianprops=mp, whiskerprops=wp, capprops=cp, flierprops=fp)\n",
    "plt.suptitle(\"\")\n",
    "p = plt.gca()\n",
    "p.set_title(\"(36months - Baseline)\", fontsize=15)\n",
    "p.set_xlabel(\"Classe (e1500)\", fontsize=15)\n",
    "p.set_ylabel(\"Broad Attention score\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
