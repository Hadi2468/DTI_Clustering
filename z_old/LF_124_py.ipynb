{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import some helpful libraries\n",
    "print(\"    Version control\\n------------------------\")\n",
    "import os, fnmatch, random, math, sys, datetime\n",
    "from pathlib import Path\n",
    "import numpy as np;              print(\"Numpy\\t\\t\", np.__version__)\n",
    "import matplotlib as mpl;        print(\"matplotlib\\t\", mpl.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd;             print(\"Pandas\\t\\t {}\".format(pd.__version__))\n",
    "import h5py;                     print(\"H5py\\t\\t {}\".format(h5py.__version__))\n",
    "import tensorflow as tf;         print(\"TensorFlow\\t {}\".format(tf.__version__))\n",
    "import keras;                    print(\"Keras\\t\\t {}\".format(keras.__version__))\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import models, Input, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, BatchNormalization, Conv3D, MaxPooling3D, UpSampling3D, ZeroPadding3D\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load all data\n",
    "sample_name = np.loadtxt(('../Data/data_random_1/raw_data/all_sample_name.csv'), dtype=str, delimiter=\",\")\n",
    "all_data = np.load('../Data/data_random_1/raw_data/all.npy').reshape(124,182,218,182,1)\n",
    "print('all_data shape is {}'.format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Padding datasets\n",
    "all_pad_data = (ZeroPadding3D(padding=(5,19,5))(all_data)).numpy()\n",
    "print('all_padded_data shape is {}'.format(all_pad_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convolutional AutoEncoder Model Designe:\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 1500\n",
    "\n",
    "IMAGE_HEIGHT = all_pad_data.shape[1]\n",
    "IMAGE_WIDTH  = all_pad_data.shape[2]\n",
    "IMAGE_DEPTH  = all_pad_data.shape[3]\n",
    "data_shape = [1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, 1]\n",
    "input_shape = [BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, 1]\n",
    "print(\"Padded data shape: {}\\n\".format(input_shape))\n",
    "\n",
    "## Encoder\n",
    "input_img = Input(shape=(192, 256, 192, 1), name='Input')\n",
    "x1 = Conv3D(filters=128, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv1')(input_img)\n",
    "x1 = BatchNormalization(name='BN_Conv1')(x1)\n",
    "x2 = Conv3D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv2')(x1)\n",
    "x2 = BatchNormalization(name='BN_Conv2')(x2)\n",
    "x3 = Conv3D(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv3')(x2)\n",
    "x3 = BatchNormalization(name='BN_Conv3')(x3)\n",
    "x4 = Conv3D(filters=16, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv4')(x3)\n",
    "x4 = BatchNormalization(name='BN_Conv4')(x4)\n",
    "\n",
    "## Latent Features\n",
    "shape_before_flattening = tf.keras.backend.int_shape(x4)\n",
    "x_LF = Flatten(name='LF')(x4)\n",
    "encoded = x_LF\n",
    "x5 = Reshape(shape_before_flattening[1:], name='UnFlat')(encoded)\n",
    "\n",
    "## Decoder\n",
    "x5 = Conv3D(filters=16, kernel_size=3, padding='same', activation='relu', name='DeConv3')(x5)\n",
    "x5 = BatchNormalization(name='BN_DeConv3')(x5)\n",
    "x5 = UpSampling3D(size=(2, 2, 2), name='UpSampling3')(x5)\n",
    "x6 = Conv3D(filters=32, kernel_size=3, padding='same', activation='relu', name='DeConv4')(x5)\n",
    "x6 = BatchNormalization(name='BN_DeConv4')(x6)\n",
    "x6 = UpSampling3D(size=(2, 2, 2), name='UpSampling4')(x6)\n",
    "x7 = Conv3D(filters=64, kernel_size=3, padding='same', activation='relu', name='DeConv5')(x6)\n",
    "x7 = BatchNormalization(name='BN_DeConv5')(x7)\n",
    "x7 = UpSampling3D(size=(2, 2, 2), name='UpSampling5')(x7)\n",
    "x8 = Conv3D(filters=128, kernel_size=3, padding='same', activation='relu', name='DeConv6')(x7)\n",
    "x8 = BatchNormalization(name='BN_DeConv6')(x8)\n",
    "x8 = UpSampling3D(size=(2, 2, 2), name='UpSampling6')(x8)\n",
    "decoded = Conv3D(filters=1, kernel_size=3, padding='same', activation='sigmoid', name='Output')(x8)\n",
    "\n",
    "model_CAE = Model(inputs=input_img, outputs=decoded, name='AutoEncoder')\n",
    "## optimizer=rmsprop, sgd\n",
    "model_CAE.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model_CAE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start time:\n",
    "from datetime import datetime\n",
    "start_time = datetime.now().strftime(\"%Y_%m_%d___%H_%M\"); print(\"\\nStart Time =\", start_time, \"\\n\")\n",
    "\n",
    "## Model Fit\n",
    "# model_CAE.load_weights('./Weights/all___2021_01_07___11_42.hdf5', by_name=True)  # epochs 1001_1500\n",
    "tb_callback = TensorBoard(('./Logs/all___' + start_time), histogram_freq=1)\n",
    "model_CAE.fit(all_pad_data, all_pad_data, epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True, callbacks=[tb_callback], verbose=1)\n",
    "# model_CAE.fit(train_pad_data, train_pad_data, validation_data=(valid_pad_data, valid_pad_data), epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True, callbacks=[tb_callback, model_checkpoint_callback], verbose=1)\n",
    "model_CAE.save_weights('./Weights/all___' + start_time + '.hdf5')\n",
    "\n",
    "## End time:\n",
    "from datetime import datetime\n",
    "end_time = datetime.now().strftime(\"%Y_%m_%d___%H_%M\"); print(\"\\nEnd Time =\", end_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
