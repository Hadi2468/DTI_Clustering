{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import some helpful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Version control\n",
      "------------------------\n",
      "Numpy\t\t 1.19.4\n",
      "matplotlib\t 3.3.3\n",
      "NiBabel\t\t 3.2.0\n",
      "Pandas\t\t 1.1.4\n",
      "imageio\t\t 2.9.0\n",
      "H5py\t\t 2.10.0\n",
      "Scikit-learn\t 0.23.2\n",
      "Scikit-image\t 0.17.2\n",
      "TensorFlow\t 2.4.0\n",
      "Keras\t\t 2.4.3\n"
     ]
    }
   ],
   "source": [
    "## Import some helpful libraries\n",
    "print(\"    Version control\\n------------------------\")\n",
    "import os, fnmatch, random, math, sys, datetime\n",
    "from pathlib import Path\n",
    "import numpy as np;              print(\"Numpy\\t\\t\", np.__version__)\n",
    "import matplotlib as mpl;        print(\"matplotlib\\t\", mpl.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib;           print(\"NiBabel\\t\\t {}\".format(nib.__version__))\n",
    "from nibabel.testing import data_path\n",
    "import pandas as pd;             print(\"Pandas\\t\\t {}\".format(pd.__version__))\n",
    "import imageio;                  print(\"imageio\\t\\t {}\".format(imageio.__version__))\n",
    "import h5py;                     print(\"H5py\\t\\t {}\".format(h5py.__version__))\n",
    "import sklearn;                  print(\"Scikit-learn\\t {}\".format(sklearn.__version__))\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import skimage;                  print(\"Scikit-image\\t {}\".format(skimage.__version__))\n",
    "import tensorflow as tf;         print(\"TensorFlow\\t {}\".format(tf.__version__))\n",
    "import keras;                    print(\"Keras\\t\\t {}\".format(keras.__version__))\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import models, Input, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, BatchNormalization, Conv3D, MaxPooling3D, UpSampling3D, ZeroPadding3D\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "# %load_ext tensorboard       \n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuroCognitive Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Loading original Neurocognitive score data\n",
    "\n",
    "# score_df = pd.read_excel('./Data/Neurocognitive_Scores/Scores_original.xlsx')\n",
    "# df = score_df\n",
    "# for p in range (len(df)):\n",
    "#     if df.ID[p][5] == '_': \n",
    "#         df.ID[p] = df.ID[p][0:4] + '00' + df.ID[p][4:]\n",
    "#     elif df.ID[p][6] == '_': \n",
    "#         df.ID[p] = df.ID[p][0:4] + '0' + df.ID[p][4:]\n",
    "# print('\\033[1m There are totally {} records\\n'.format(len(df)))\n",
    "\n",
    "# ## Extract the Baseline_Phase and save\n",
    "# df = df.rename(columns={'Phase Description':'Phase_Description', 'GIA SS':'GIA_SS', 'Proc Spd SS':'Proc_Spd_SS', 'Working Mem SS':'Working_Mem_SS', 'Broad Attn SS':'Broad_Attn_SS'})\n",
    "# df.index = df[df.columns[0]]\n",
    "# df = df.drop(['ID'], axis=1)\n",
    "# df = df.drop(['Date'], axis=1)\n",
    "# df_base = df[(df.Phase_Description == 'Baseline phase') | (df.Phase_Description == 'Baseline Phase')]\n",
    "# df_base.Phase_Description = 'baseline_phase'\n",
    "# print('\\033[1m There are {} records of baseline_phasse\\n'.format(len(df_base)))\n",
    "# df_base.to_csv((r'./Data/Neurocognitive_Scores/baseline.csv'))\n",
    "\n",
    "# ## Extract the 36_months_Phase and save\n",
    "# df_36 = df[(df.Phase_Description == 'Post Dx 36 months')]# | (df.Phase_Description == 'Baseline Phase')]\n",
    "# df_36.Phase_Description = '36_months'\n",
    "# print('\\033[1m There are {} records of 36_months\\n'.format(len(df_36)))\n",
    "# df_36.to_csv((r'./Data/Neurocognitive_Scores/m36.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m There are 82 records of Baseline_phase\n",
      "\n",
      "\u001b[1m Among 82 records of Baseline_phase, there are 78 records for GIA_Score\n",
      "\u001b[1m Among 82 records of Baseline_phase, there are 74 records for Process_Spead_Score\n",
      "\u001b[1m Among 82 records of Baseline_phase, there are 74 records for Working_Memory_Score\n",
      "\u001b[1m Among 82 records of Baseline_phase, there are 66 records for Broad_Attention_Score\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Developing Scores for Baseline\n",
    "\n",
    "df_base = pd.read_csv('./Data/Neurocognitive_Scores/baseline.csv')\n",
    "print('\\033[1m There are {} records of Baseline_phase\\n'.format(len(df_base)))\n",
    "df_base.index = df_base.ID\n",
    "# df_base\n",
    "\n",
    "## Baseline_phasse & GIA_Score\n",
    "df_base_GIA = df_base.GIA_SS\n",
    "df_base_GIA = df_base_GIA.dropna()   # remove NaN\n",
    "df_base_GIA = df_base_GIA.astype(int)\n",
    "print('\\033[1m Among {} records of Baseline_phase,'.format(len(df_base)) , 'there are {} records for GIA_Score'.format(len(df_base_GIA)))\n",
    "# df_base_GIA.to_csv((r'./Data/Neurocognitive_Scores/baseline_GIA.csv'))\n",
    "\n",
    "## Baseline_phasse & Process_Spead_Score\n",
    "df_base_Proc_Spd = df_base.Proc_Spd_SS\n",
    "df_base_Proc_Spd = df_base_Proc_Spd.dropna()   # remove NaN\n",
    "df_base_Proc_Spd = df_base_Proc_Spd.astype(int)\n",
    "print('\\033[1m Among {} records of Baseline_phase,'.format(len(df_base)) , 'there are {} records for Process_Spead_Score'.format(len(df_base_Proc_Spd)))\n",
    "# df_base_Proc_Spd.to_csv((r'./Data/Neurocognitive_Scores/baseline_Proc_Spd.csv'))\n",
    "\n",
    "## Baseline_phasse & Working_Memory_Score\n",
    "df_base_Working_Mem = df_base.Working_Mem_SS\n",
    "df_base_Working_Mem = df_base_Working_Mem.dropna()   # remove NaN\n",
    "df_base_Working_Mem = df_base_Working_Mem.astype(int)\n",
    "print('\\033[1m Among {} records of Baseline_phase,'.format(len(df_base)) , 'there are {} records for Working_Memory_Score'.format(len(df_base_Working_Mem)))\n",
    "# df_base_Working_Mem.to_csv((r'./Data/Neurocognitive_Scores/baseline_Working_Mem.csv'))\n",
    "\n",
    "## Baseline_phasse & Broad_Attention_Score\n",
    "df_base_Broad_Attn = df_base.Broad_Attn_SS\n",
    "df_base_Broad_Attn = df_base_Broad_Attn.dropna()   # remove NaN\n",
    "df_base_Broad_Attn = df_base_Broad_Attn.astype(int)\n",
    "print('\\033[1m Among {} records of Baseline_phase,'.format(len(df_base)) , 'there are {} records for Broad_Attention_Score\\n'.format(len(df_base_Broad_Attn)))\n",
    "# df_base_Broad_Attn.to_csv((r'./Data/Neurocognitive_Scores/baseline_Broad_Attn.csv'))\n",
    "# df_base_Broad_Attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m There are 80 records for Month-36 \n",
      "\n",
      "\u001b[1m Among 80 records of Month-36, there are 79 records for GIA_Score\n",
      "\u001b[1m Among 80 records of Month-36, there are 78 records for Process_Spead_Score\n",
      "\u001b[1m Among 80 records of Month-36, there are 78 records for Working_Memory_Score\n",
      "\u001b[1m Among 80 records of Month-36, there are 75 records for Broad_Attention_Score\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Developing Scores for 36_Months\n",
    "\n",
    "df_m36 = pd.read_csv('./Data/Neurocognitive_Scores/m36.csv')\n",
    "\n",
    "print('\\033[1m There are {} records for Month-36 \\n'.format(len(df_m36)))\n",
    "df_m36.index = df_m36.ID\n",
    "\n",
    "## Month-36 & GIA_Score\n",
    "df_m36_GIA = df_m36.GIA_SS\n",
    "df_m36_GIA = df_m36_GIA.dropna()   # remove NaN\n",
    "df_m36_GIA = df_m36_GIA.astype(int)\n",
    "print('\\033[1m Among {} records of Month-36,'.format(len(df_m36)) , 'there are {} records for GIA_Score'.format(len(df_m36_GIA)))\n",
    "df_m36_GIA.to_csv((r'./Data/Neurocognitive_Scores/m36_GIA.csv'))\n",
    "\n",
    "## Month-36 & Process_Spead_Score\n",
    "df_m36_Proc_Spd = df_m36.Proc_Spd_SS\n",
    "df_m36_Proc_Spd = df_m36_Proc_Spd.dropna()   # remove NaN\n",
    "df_m36_Proc_Spd = df_m36_Proc_Spd.astype(int)\n",
    "print('\\033[1m Among {} records of Month-36,'.format(len(df_m36)) , 'there are {} records for Process_Spead_Score'.format(len(df_m36_Proc_Spd)))\n",
    "df_m36_Proc_Spd.to_csv((r'./Data/Neurocognitive_Scores/m36_Proc_Spd.csv'))\n",
    "\n",
    "## Month-36 & Working_Memory_Score\n",
    "df_m36_Working_Mem = df_m36.Working_Mem_SS\n",
    "df_m36_Working_Mem = df_m36_Working_Mem.dropna()   # remove NaN\n",
    "df_m36_Working_Mem = df_m36_Working_Mem.astype(int)\n",
    "print('\\033[1m Among {} records of Month-36,'.format(len(df_m36)) , 'there are {} records for Working_Memory_Score'.format(len(df_m36_Working_Mem)))\n",
    "df_m36_Working_Mem.to_csv((r'./Data/Neurocognitive_Scores/m36_Working_Mem.csv'))\n",
    "\n",
    "## Month-36 & Broad_Attention_Score\n",
    "df_m36_Broad_Attn = df_m36.Broad_Attn_SS\n",
    "df_m36_Broad_Attn = df_m36_Broad_Attn.dropna()   # remove NaN\n",
    "df_m36_Broad_Attn = df_m36_Broad_Attn.astype(int)\n",
    "print('\\033[1m Among {} records of Month-36,'.format(len(df_m36)) , 'there are {} records for Broad_Attention_Score\\n'.format(len(df_m36_Broad_Attn)))\n",
    "df_m36_Broad_Attn.to_csv((r'./Data/Neurocognitive_Scores/m36_Broad_Attn.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Among 80 records of Month-36, and 82 records of Baseline-Phase, there are 58 common records for GIA Score\n",
      "\u001b[1m Among 80 records of Month-36, and 82 records of Baseline-Phase, there are 54 common records for Process Speed Score\n",
      "\u001b[1m Among 80 records of Month-36, and 82 records of Baseline-Phase, there are 56 common records for Working Memory Score\n",
      "\u001b[1m Among 80 records of Month-36, and 82 records of Baseline-Phase, there are 49 common records for Broad Attention Score\n"
     ]
    }
   ],
   "source": [
    "## Developing Scores for (36_Months - Baseline_Phase)\n",
    "\n",
    "## m36-base & GIA_Score\n",
    "df_base_GIA = pd.read_csv('./Data/Neurocognitive_Scores/baseline_GIA.csv')\n",
    "df_m36_GIA = pd.read_csv('./Data/Neurocognitive_Scores/m36_GIA.csv')\n",
    "# print(df_m36_GIA)\n",
    "# print(df_base_GIA)\n",
    "df_m36_join_base_GIA = pd.merge(df_m36_GIA, df_base_GIA, how='inner', on=['ID'])\n",
    "df_m36_join_base_GIA['GIA_SS'] = df_m36_join_base_GIA.GIA_SS_x - df_m36_join_base_GIA.GIA_SS_y \n",
    "print('\\033[1m Among {} records of Month-36,'.format(len(df_m36)) , 'and {} records of Baseline-Phase,'.format(len(df_base)),\n",
    "      'there are {} common records for GIA Score'.format(len(df_m36_join_base_GIA)))\n",
    "# print(df_m36_join_base_GIA)\n",
    "df_m36_base_GIA = df_m36_join_base_GIA.drop(['GIA_SS_x', 'GIA_SS_y'], axis=1)\n",
    "# df_m36_base_GIA.to_csv((r'./Data/Neurocognitive_Scores/m36_base_GIA.csv'))\n",
    "\n",
    "## m36-base & Process_Spead_Score\n",
    "df_base_Proc_Spd = pd.read_csv('./Data/Neurocognitive_Scores/baseline_Proc_Spd.csv')\n",
    "df_m36_Proc_Spd = pd.read_csv('./Data/Neurocognitive_Scores/m36_Proc_Spd.csv')\n",
    "# print(df_m36_Proc_Spd)\n",
    "# print(df_base_Proc_Spd)\n",
    "df_m36_join_base_Proc_Spd = pd.merge(df_m36_Proc_Spd, df_base_Proc_Spd, how='inner', on=['ID'])\n",
    "df_m36_join_base_Proc_Spd['Proc_Spd_SS'] = df_m36_join_base_Proc_Spd.Proc_Spd_SS_x - df_m36_join_base_Proc_Spd.Proc_Spd_SS_y \n",
    "print('\\033[1m Among {} records of Month-36,'.format(len(df_m36)) , 'and {} records of Baseline-Phase,'.format(len(df_base)),\n",
    "      'there are {} common records for Process Speed Score'.format(len(df_m36_join_base_Proc_Spd)))\n",
    "# print(df_m36_join_base_Proc_Spd)\n",
    "df_m36_base_Proc_Spd = df_m36_join_base_Proc_Spd.drop(['Proc_Spd_SS_x', 'Proc_Spd_SS_y'], axis=1)\n",
    "# df_m36_base_Proc_Spd.to_csv((r'./Data/Neurocognitive_Scores/m36_base_ProcSpd.csv'))\n",
    "\n",
    "## m36-base & Working_Memory_Score\n",
    "df_base_Working_Mem = pd.read_csv('./Data/Neurocognitive_Scores/baseline_Working_Mem.csv')\n",
    "df_m36_Working_Mem = pd.read_csv('./Data/Neurocognitive_Scores/m36_Working_Mem.csv')\n",
    "# print(df_m36_Working_Mem)\n",
    "# print(df_base_Working_Mem)\n",
    "df_m36_join_base_Working_Mem = pd.merge(df_m36_Working_Mem, df_base_Working_Mem, how='inner', on=['ID'])\n",
    "df_m36_join_base_Working_Mem['Working_Mem_SS'] = df_m36_join_base_Working_Mem.Working_Mem_SS_x - df_m36_join_base_Working_Mem.Working_Mem_SS_y \n",
    "print('\\033[1m Among {} records of Month-36,'.format(len(df_m36)) , 'and {} records of Baseline-Phase,'.format(len(df_base)),\n",
    "      'there are {} common records for Working Memory Score'.format(len(df_m36_join_base_Working_Mem)))\n",
    "# print(df_m36_join_base_Working_Mem)\n",
    "df_m36_base_Working_Mem = df_m36_join_base_Working_Mem.drop(['Working_Mem_SS_x', 'Working_Mem_SS_y'], axis=1)\n",
    "# df_m36_base_Working_Mem.to_csv((r'./Data/Neurocognitive_Scores/m36_base_WorkingMem.csv'))\n",
    "\n",
    "## m36-base & Broad_Attention_Score\n",
    "df_base_Broad_Attn = pd.read_csv('./Data/Neurocognitive_Scores/baseline_Broad_Attn.csv')\n",
    "df_m36_Broad_Attn = pd.read_csv('./Data/Neurocognitive_Scores/m36_Broad_Attn.csv')\n",
    "# print(df_m36_Broad_Attn)\n",
    "# print(df_base_Broad_Attn)\n",
    "df_m36_join_base_Broad_Attn = pd.merge(df_m36_Broad_Attn, df_base_Broad_Attn, how='inner', on=['ID'])\n",
    "df_m36_join_base_Broad_Attn['Broad_Attn_SS'] = df_m36_join_base_Broad_Attn.Broad_Attn_SS_x - df_m36_join_base_Broad_Attn.Broad_Attn_SS_y \n",
    "print('\\033[1m Among {} records of Month-36,'.format(len(df_m36)) , 'and {} records of Baseline-Phase,'.format(len(df_base)),\n",
    "      'there are {} common records for Broad Attention Score'.format(len(df_m36_join_base_Broad_Attn)))\n",
    "# print(df_m36_join_base_Broad_Attn)\n",
    "df_m36_base_Broad_Attn = df_m36_join_base_Working_Mem.drop(['Working_Mem_SS_x', 'Working_Mem_SS_y'], axis=1)\n",
    "# df_m36_base_Broad_Attn.to_csv((r'./Data/Neurocognitive_Scores/m36_base_BroadAttn.csv'))\n",
    "# df_m36_base_Broad_Attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
