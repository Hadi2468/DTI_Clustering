{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Version control\n",
      "------------------------\n",
      "Numpy\t\t 1.19.4\n",
      "matplotlib\t 3.3.3\n",
      "NiBabel\t\t 3.2.0\n",
      "Pandas\t\t 1.1.4\n",
      "imageio\t\t 2.9.0\n",
      "H5py\t\t 2.10.0\n",
      "Scikit-learn\t 0.23.2\n",
      "Scikit-image\t 0.17.2\n",
      "TensorFlow\t 2.3.1\n",
      "Keras\t\t 2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "print(\"    Version control\\n------------------------\")\n",
    "import os, fnmatch, random, math, sys, datetime\n",
    "from pathlib import Path\n",
    "import numpy as np;              print(\"Numpy\\t\\t\", np.__version__)\n",
    "import matplotlib as mpl;        print(\"matplotlib\\t\", mpl.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib;           print(\"NiBabel\\t\\t {}\".format(nib.__version__))\n",
    "from nibabel.testing import data_path\n",
    "import pandas as pd;             print(\"Pandas\\t\\t {}\".format(pd.__version__))\n",
    "import imageio;                  print(\"imageio\\t\\t {}\".format(imageio.__version__))\n",
    "import h5py;                     print(\"H5py\\t\\t {}\".format(h5py.__version__))\n",
    "import sklearn;                  print(\"Scikit-learn\\t {}\".format(sklearn.__version__))\n",
    "import skimage;                  print(\"Scikit-image\\t {}\".format(skimage.__version__))\n",
    "import tensorflow as tf;         print(\"TensorFlow\\t {}\".format(tf.__version__))\n",
    "import keras as K;               print(\"Keras\\t\\t {}\".format(K.__version__))\n",
    "from tensorflow.keras import models, Input, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, BatchNormalization, Conv3D, MaxPooling3D, UpSampling3D\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.initializers import *\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "#%load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape is (100, 182, 218, 182, 1)\n",
      "valid_data shape is (24, 182, 218, 182, 1)\n"
     ]
    }
   ],
   "source": [
    "## Load train data\n",
    "sample_train_subset = np.loadtxt(\"sample_train_1.csv\", dtype=str, delimiter=\",\")\n",
    "train_data = np.load('train_1.npy').reshape(100,182,218,182,1)\n",
    "print('train_data shape is {}'.format(train_data.shape))\n",
    "\n",
    "## Load validation data\n",
    "sample_val_subset = np.loadtxt(\"sample_valid_1.csv\", dtype=str, delimiter=\",\")\n",
    "valid_data = np.load('valid_1.npy').reshape(24,182,218,182,1)\n",
    "print('valid_data shape is {}'.format(valid_data.shape))\n",
    "\n",
    "## Load last weights\n",
    "# last_weights = str(Path(os.path.join(os.getcwd(), \"Weights\")) / \"w_1.hdf5\")\n",
    "# print(last_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input-layer shape: [1, 182, 218, 182, 1]\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 182, 218, 182, 1) 0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv3D)               (None, 91, 109, 91, 128)  3584      \n",
      "_________________________________________________________________\n",
      "BN_Conv1 (BatchNormalization (None, 91, 109, 91, 128)  512       \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv3D)               (None, 46, 55, 46, 64)    221248    \n",
      "_________________________________________________________________\n",
      "BN_Conv2 (BatchNormalization (None, 46, 55, 46, 64)    256       \n",
      "_________________________________________________________________\n",
      "Conv3 (Conv3D)               (None, 23, 28, 23, 32)    55328     \n",
      "_________________________________________________________________\n",
      "BN_Conv3 (BatchNormalization (None, 23, 28, 23, 32)    128       \n",
      "_________________________________________________________________\n",
      "Conv4 (Conv3D)               (None, 12, 14, 12, 16)    13840     \n",
      "_________________________________________________________________\n",
      "BN_Conv4 (BatchNormalization (None, 12, 14, 12, 16)    64        \n",
      "_________________________________________________________________\n",
      "Conv5 (Conv3D)               (None, 6, 7, 6, 8)        3464      \n",
      "_________________________________________________________________\n",
      "BN_Conv5 (BatchNormalization (None, 6, 7, 6, 8)        32        \n",
      "_________________________________________________________________\n",
      "Conv6 (Conv3D)               (None, 3, 4, 3, 4)        868       \n",
      "_________________________________________________________________\n",
      "BN_Conv6 (BatchNormalization (None, 3, 4, 3, 4)        16        \n",
      "_________________________________________________________________\n",
      "Flat (Flatten)               (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "UnFlat (Reshape)             (None, 3, 4, 3, 4)        0         \n",
      "_________________________________________________________________\n",
      "DeConv1 (Conv3D)             (None, 3, 4, 3, 4)        436       \n",
      "_________________________________________________________________\n",
      "BN_DeConv1 (BatchNormalizati (None, 3, 4, 3, 4)        16        \n",
      "_________________________________________________________________\n",
      "UpSampling1 (UpSampling3D)   (None, 6, 8, 6, 4)        0         \n",
      "_________________________________________________________________\n",
      "DeConv2 (Conv3D)             (None, 6, 7, 6, 8)        72        \n",
      "_________________________________________________________________\n",
      "BN_DeConv2 (BatchNormalizati (None, 6, 7, 6, 8)        32        \n",
      "_________________________________________________________________\n",
      "UpSampling2 (UpSampling3D)   (None, 12, 14, 12, 8)     0         \n",
      "_________________________________________________________________\n",
      "DeConv3 (Conv3D)             (None, 12, 14, 12, 16)    3472      \n",
      "_________________________________________________________________\n",
      "BN_DeConv3 (BatchNormalizati (None, 12, 14, 12, 16)    64        \n",
      "_________________________________________________________________\n",
      "UpSampling3 (UpSampling3D)   (None, 24, 28, 24, 16)    0         \n",
      "_________________________________________________________________\n",
      "DeConv4 (Conv3D)             (None, 23, 28, 23, 32)    2080      \n",
      "_________________________________________________________________\n",
      "BN_DeConv4 (BatchNormalizati (None, 23, 28, 23, 32)    128       \n",
      "_________________________________________________________________\n",
      "UpSampling4 (UpSampling3D)   (None, 46, 56, 46, 32)    0         \n",
      "_________________________________________________________________\n",
      "DeConv5 (Conv3D)             (None, 46, 55, 46, 64)    4160      \n",
      "_________________________________________________________________\n",
      "BN_DeConv5 (BatchNormalizati (None, 46, 55, 46, 64)    256       \n",
      "_________________________________________________________________\n",
      "UpSampling5 (UpSampling3D)   (None, 92, 110, 92, 64)   0         \n",
      "_________________________________________________________________\n",
      "DeConv6 (Conv3D)             (None, 91, 109, 91, 128)  65664     \n",
      "_________________________________________________________________\n",
      "BN_DeConv6 (BatchNormalizati (None, 91, 109, 91, 128)  512       \n",
      "_________________________________________________________________\n",
      "UpSampling6 (UpSampling3D)   (None, 182, 218, 182, 128 0         \n",
      "_________________________________________________________________\n",
      "Output (Conv3D)              (None, 182, 218, 182, 1)  3457      \n",
      "=================================================================\n",
      "Total params: 379,689\n",
      "Trainable params: 378,681\n",
      "Non-trainable params: 1,008\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Define parameters:\n",
    "\n",
    "IMAGE_HEIGHT = train_data.shape[1]\n",
    "IMAGE_WIDTH = train_data.shape[2]\n",
    "IMAGE_DEPTH = train_data.shape[3]\n",
    "batch_size = 1\n",
    "data_shape = [1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, 1]\n",
    "input_shape = [batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, 1]\n",
    "print(\"input-layer shape:\", input_shape)\n",
    "\n",
    "## Encoder\n",
    "input_img = Input(shape=(182, 218, 182, 1), name='Input')\n",
    "x = Conv3D(filters=128, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv1')(input_img)\n",
    "x = BatchNormalization(name='BN_Conv1')(x)\n",
    "x = Conv3D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv2')(x)\n",
    "x = BatchNormalization(name='BN_Conv2')(x)\n",
    "x = Conv3D(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv3')(x)\n",
    "x = BatchNormalization(name='BN_Conv3')(x)\n",
    "x = Conv3D(filters=16, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv4')(x)\n",
    "x = BatchNormalization(name='BN_Conv4')(x)\n",
    "x = Conv3D(filters=8, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv5')(x)\n",
    "x = BatchNormalization(name='BN_Conv5')(x)\n",
    "x = Conv3D(filters=4, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv6')(x)\n",
    "x = BatchNormalization(name='BN_Conv6')(x)\n",
    "\n",
    "## Latent Features\n",
    "shape_before_flattening = tf.keras.backend.int_shape(x)\n",
    "x = Flatten(name='Flat')(x)\n",
    "# init = VarianceScaling(scale=1. / 3., mode='fan_in', distribution='uniform')\n",
    "# encoded = Dense(50, kernel_initializer=init, activation='relu', name='encoded')(x)\n",
    "# encoded = Dense(50, activation='relu', name='encoded')(x)\n",
    "encoded = x\n",
    "# x = BatchNormalization()(encoded)\n",
    "# x = Dense(np.prod(shape_before_flattening[1:]), activation='relu', kernel_initializer=init)(encoded)\n",
    "# x = Dense(np.prod(shape_before_flattening[1:]), activation='relu')(encoded)\n",
    "x = Reshape(shape_before_flattening[1:], name='UnFlat')(x)\n",
    "\n",
    "## Decoder\n",
    "x = Conv3D(filters=4, kernel_size=3, padding='same', activation='relu', name='DeConv1')(x)\n",
    "x = BatchNormalization(name='BN_DeConv1')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling1')(x)\n",
    "x = Conv3D(filters=8, kernel_size=(1,2,1), padding='valid', activation='relu', name='DeConv2')(x)\n",
    "x = BatchNormalization(name='BN_DeConv2')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling2')(x)\n",
    "x = Conv3D(filters=16, kernel_size=3, padding='same', activation='relu', name='DeConv3')(x)\n",
    "x = BatchNormalization(name='BN_DeConv3')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling3')(x)\n",
    "x = Conv3D(filters=32, kernel_size=(2,1,2), padding='valid', activation='relu', name='DeConv4')(x)\n",
    "x = BatchNormalization(name='BN_DeConv4')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling4')(x)\n",
    "x = Conv3D(filters=64, kernel_size=(1,2,1), padding='valid', activation='relu', name='DeConv5')(x)\n",
    "x = BatchNormalization(name='BN_DeConv5')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling5')(x)\n",
    "x = Conv3D(filters=128, kernel_size=2, padding='valid', activation='relu', name='DeConv6')(x)\n",
    "x = BatchNormalization(name='BN_DeConv6')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling6')(x)\n",
    "decoded = Conv3D(filters=1, kernel_size=3, padding='same', activation='sigmoid', name='Output')(x)\n",
    "\n",
    "model_CAE = Model(inputs=input_img, outputs=decoded)\n",
    "## optimizer=rmsprop, sgd\n",
    "model_CAE.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model_CAE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start time:\n",
    "from datetime import datetime\n",
    "start_time = datetime.now().strftime(\"%Y.%m.%d___%H:%M\")\n",
    "print(\"\\nStart Time =\", start_time, \"\\n\")\n",
    "\n",
    "## Loading last weights\n",
    "# model_CAE.load_weights(os.path.join(\"Weights/Weights_L100___2020_12_30___03_43_23.hdf5\"))\n",
    "\n",
    "## Model Fit\n",
    "tb_callback = TensorBoard(os.path.join(\"Logs/L100___\" + start_time), histogram_freq=1)\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=5, mode='auto')\n",
    "model_CAE.fit(train_data, train_data, validation_data=(valid_data, valid_data), epochs=1, batch_size=batch_size, shuffle=True, callbacks=[tb_callback], verbose=1)\n",
    "model_CAE.save_weights(os.path.join(\"Weights/L100___\" + start_time + \".hdf5\"))\n",
    "\n",
    "## End time:\n",
    "from datetime import datetime\n",
    "end_time = datetime.now().strftime(\"%Y_%m_%d____%H_%M\")\n",
    "print(\"\\nEnd Time =\", end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = train_data[0,:].reshape(1, 182, 218, 182, 1)\n",
    "reconstructed = model_CAE.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_data[0,100,100:105,100]\n",
      "\n",
      " [[0.55211586]\n",
      " [0.51723999]\n",
      " [0.52700305]\n",
      " [0.62761533]\n",
      " [0.59050184]] \n",
      "\n",
      "\n",
      "Reconstructed_data[0,100,100:105,100]\n",
      "\n",
      " [[0.50004554]\n",
      " [0.50004554]\n",
      " [0.50004554]\n",
      " [0.50004554]\n",
      " [0.50004554]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\ntrain_data[0,100,100:105,100]\\n\\n {}'.format(train_data[0,100,100:105,100]),'\\n')\n",
    "print('\\nReconstructed_data[0,100,100:105,100]\\n\\n {}'.format(reconstructed[0,100,100:105,100]),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17 layers in this model as:\n",
      "\n",
      " ['Conv1', 'Conv2', 'Conv3', 'DeConv1', 'DeConv2', 'DeConv3', 'Output', 'batch_normalization', 'batch_normalization_1', 'batch_normalization_2', 'batch_normalization_3', 'batch_normalization_4', 'batch_normalization_5', 'input_1', 'up_sampling3d', 'up_sampling3d_1', 'up_sampling3d_2'] \n",
      "\n",
      "==========================================================\n",
      "\n",
      "Layer 1 : Conv1 \tWeights' shape: (3, 3, 3, 1, 64) \n",
      "\n",
      "\n",
      "Weights of kernel 1 of 64 :\n",
      "\n",
      " [[[-0.03236854 -0.14316913 -0.13911112]\n",
      "  [-0.05437694  0.00110877  0.02125892]\n",
      "  [-0.02176703  0.04296681  0.04505903]]\n",
      "\n",
      " [[ 0.0099239  -0.07856947 -0.0984294 ]\n",
      "  [-0.00154239 -0.02180088 -0.02031503]\n",
      "  [-0.01293995 -0.01628701  0.02513998]]\n",
      "\n",
      " [[ 0.26138464  0.16107135  0.12669967]\n",
      "  [ 0.3406086   0.24986073  0.20581758]\n",
      "  [ 0.19243112  0.21549019  0.13506231]]]\n",
      "\n",
      "Weights of kernel 2 of 64 :\n",
      "\n",
      " [[[-0.03236854 -0.14316913 -0.13911112]\n",
      "  [-0.05437694  0.00110877  0.02125892]\n",
      "  [-0.02176703  0.04296681  0.04505903]]\n",
      "\n",
      " [[ 0.0099239  -0.07856947 -0.0984294 ]\n",
      "  [-0.00154239 -0.02180088 -0.02031503]\n",
      "  [-0.01293995 -0.01628701  0.02513998]]\n",
      "\n",
      " [[ 0.26138464  0.16107135  0.12669967]\n",
      "  [ 0.3406086   0.24986073  0.20581758]\n",
      "  [ 0.19243112  0.21549019  0.13506231]]]\n",
      "==========================================================\n",
      "\n",
      "Layer 2 : Conv2 \tWeights' shape: (3, 3, 3, 64, 32) \n",
      "\n",
      "\n",
      "Weights of kernel 1 of 32 :\n",
      "\n",
      " [[[-0.08327673 -0.00606304 -0.17375828]\n",
      "  [ 0.00915497  0.10366923 -0.03863918]\n",
      "  [-0.14463937  0.09929734 -0.01059491]]\n",
      "\n",
      " [[ 0.0089658   0.13530472 -0.00542113]\n",
      "  [ 0.05909272  0.28686208  0.12015411]\n",
      "  [-0.15417181  0.19223987  0.04727878]]\n",
      "\n",
      " [[-0.04803416  0.1227417  -0.06543531]\n",
      "  [ 0.17368579  0.3834185   0.11211286]\n",
      "  [-0.01608117  0.27179658  0.06320248]]]\n",
      "\n",
      "Weights of kernel 2 of 32 :\n",
      "\n",
      " [[[-0.08327673 -0.00606304 -0.17375828]\n",
      "  [ 0.00915497  0.10366923 -0.03863918]\n",
      "  [-0.14463937  0.09929734 -0.01059491]]\n",
      "\n",
      " [[ 0.0089658   0.13530472 -0.00542113]\n",
      "  [ 0.05909272  0.28686208  0.12015411]\n",
      "  [-0.15417181  0.19223987  0.04727878]]\n",
      "\n",
      " [[-0.04803416  0.1227417  -0.06543531]\n",
      "  [ 0.17368579  0.3834185   0.11211286]\n",
      "  [-0.01608117  0.27179658  0.06320248]]]\n",
      "==========================================================\n",
      "\n",
      "Layer 3 : Conv3 \tWeights' shape: (3, 3, 3, 32, 16) \n",
      "\n",
      "\n",
      "Weights of kernel 1 of 16 :\n",
      "\n",
      " [[[-0.02888844 -0.02602053  0.05262621]\n",
      "  [-0.1569391  -0.06549618 -0.09214814]\n",
      "  [-0.08927623  0.04478442 -0.01322253]]\n",
      "\n",
      " [[-0.01958967 -0.08387411 -0.07459255]\n",
      "  [-0.04047653  0.19243634 -0.00341869]\n",
      "  [ 0.0333801   0.15988503  0.12832327]]\n",
      "\n",
      " [[-0.09747408 -0.07249939 -0.04339377]\n",
      "  [-0.19867688  0.04246155 -0.06439975]\n",
      "  [-0.11433555 -0.01961499  0.1467384 ]]]\n",
      "\n",
      "Weights of kernel 2 of 16 :\n",
      "\n",
      " [[[-0.02888844 -0.02602053  0.05262621]\n",
      "  [-0.1569391  -0.06549618 -0.09214814]\n",
      "  [-0.08927623  0.04478442 -0.01322253]]\n",
      "\n",
      " [[-0.01958967 -0.08387411 -0.07459255]\n",
      "  [-0.04047653  0.19243634 -0.00341869]\n",
      "  [ 0.0333801   0.15988503  0.12832327]]\n",
      "\n",
      " [[-0.09747408 -0.07249939 -0.04339377]\n",
      "  [-0.19867688  0.04246155 -0.06439975]\n",
      "  [-0.11433555 -0.01961499  0.1467384 ]]]\n",
      "==========================================================\n",
      "\n",
      "Layer 4 : DeConv1 \tWeights' shape: (3, 3, 3, 16, 16) \n",
      "\n",
      "\n",
      "Weights of kernel 1 of 16 :\n",
      "\n",
      " [[[ 0.07858963  0.03737931 -0.13355593]\n",
      "  [ 0.11820208  0.26219708 -0.21049519]\n",
      "  [-0.13132323  0.11174379 -0.16710261]]\n",
      "\n",
      " [[ 0.10688642 -0.08397581  0.02340166]\n",
      "  [ 0.07066747  0.09150542 -0.05515564]\n",
      "  [ 0.05734506  0.0682274   0.1242474 ]]\n",
      "\n",
      " [[ 0.04679855  0.0405114   0.05531964]\n",
      "  [-0.13678253 -0.0481918  -0.03122543]\n",
      "  [-0.29144835 -0.07757515  0.11149874]]]\n",
      "\n",
      "Weights of kernel 2 of 16 :\n",
      "\n",
      " [[[ 0.07858963  0.03737931 -0.13355593]\n",
      "  [ 0.11820208  0.26219708 -0.21049519]\n",
      "  [-0.13132323  0.11174379 -0.16710261]]\n",
      "\n",
      " [[ 0.10688642 -0.08397581  0.02340166]\n",
      "  [ 0.07066747  0.09150542 -0.05515564]\n",
      "  [ 0.05734506  0.0682274   0.1242474 ]]\n",
      "\n",
      " [[ 0.04679855  0.0405114   0.05531964]\n",
      "  [-0.13678253 -0.0481918  -0.03122543]\n",
      "  [-0.29144835 -0.07757515  0.11149874]]]\n",
      "==========================================================\n",
      "\n",
      "Layer 5 : DeConv2 \tWeights' shape: (3, 3, 3, 16, 32) \n",
      "\n",
      "\n",
      "Weights of kernel 1 of 32 :\n",
      "\n",
      " [[[ 0.06620082  0.1473276   0.15477194]\n",
      "  [ 0.11915345  0.17491181  0.15450959]\n",
      "  [ 0.16832964  0.14527316  0.09643308]]\n",
      "\n",
      " [[ 0.0995569  -0.00426724  0.1357162 ]\n",
      "  [ 0.06919719  0.08048589  0.08686256]\n",
      "  [ 0.08670706  0.07869134  0.15245436]]\n",
      "\n",
      " [[ 0.03800276  0.03710866  0.08221006]\n",
      "  [ 0.05310749  0.00059881  0.03360976]\n",
      "  [-0.05131038 -0.04569596  0.05576352]]]\n",
      "\n",
      "Weights of kernel 2 of 32 :\n",
      "\n",
      " [[[ 0.06620082  0.1473276   0.15477194]\n",
      "  [ 0.11915345  0.17491181  0.15450959]\n",
      "  [ 0.16832964  0.14527316  0.09643308]]\n",
      "\n",
      " [[ 0.0995569  -0.00426724  0.1357162 ]\n",
      "  [ 0.06919719  0.08048589  0.08686256]\n",
      "  [ 0.08670706  0.07869134  0.15245436]]\n",
      "\n",
      " [[ 0.03800276  0.03710866  0.08221006]\n",
      "  [ 0.05310749  0.00059881  0.03360976]\n",
      "  [-0.05131038 -0.04569596  0.05576352]]]\n"
     ]
    }
   ],
   "source": [
    "h5_file = h5py.File(os.path.join(\"Weights/L100___\" + start_time + \".hdf5\"), 'r')\n",
    "Layer_size = len(list(h5_file.keys()))\n",
    "Layer_names = list(h5_file.keys())\n",
    "print(\"There are\", Layer_size, \"layers in this model as:\\n\\n\", Layer_names,'\\n')\n",
    "\n",
    "for l in range(5):  #Layer_size\n",
    "    print('==========================================================\\n')\n",
    "    layers = h5_file[Layer_names[l]]\n",
    "#     print(\"Layer\", l+1, \"-----\", layers)\n",
    "    W = layers[Layer_names[l]]['kernel:0']\n",
    "    print('Layer', l+1, ':', list(h5_file.keys())[l], '\\tWeights\\' shape: {}'.format(W.shape), '\\n')\n",
    "#     print('\\nWeights[1][1][1]: {}'.format(W[1][1][1]))\n",
    "    \n",
    "    Kernel_1 = W.shape[0]\n",
    "    Kernel_2 = W.shape[1]\n",
    "    Kernel_3 = W.shape[2]\n",
    "    Kernel_all = np.zeros([Kernel_1, Kernel_2, Kernel_3])\n",
    "    for f in range(2):   # W.shape[4]\n",
    "        for x in range(Kernel_1):\n",
    "            for y in range(Kernel_2):\n",
    "                for z in range(Kernel_3):\n",
    "                    Kernel_all[x][y][z] = (W[x][y][z])[0][0]\n",
    "        print('\\nWeights of kernel', f+1, 'of', W.shape[4], ':\\n\\n', Kernel_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
