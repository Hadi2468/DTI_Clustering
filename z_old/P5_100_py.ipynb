{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Version control\n",
      "------------------------\n",
      "Numpy\t\t 1.19.4\n",
      "matplotlib\t 3.3.3\n",
      "NiBabel\t\t 3.2.0\n",
      "Pandas\t\t 1.1.4\n",
      "imageio\t\t 2.9.0\n",
      "H5py\t\t 2.10.0\n",
      "Scikit-learn\t 0.23.2\n",
      "Scikit-image\t 0.17.2\n",
      "TensorFlow\t 2.4.0\n",
      "Keras\t\t 2.4.3\n"
     ]
    }
   ],
   "source": [
    "print(\"    Version control\\n------------------------\")\n",
    "import os, fnmatch, random, math, sys, datetime\n",
    "from pathlib import Path\n",
    "import numpy as np;              print(\"Numpy\\t\\t\", np.__version__)\n",
    "import matplotlib as mpl;        print(\"matplotlib\\t\", mpl.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib;           print(\"NiBabel\\t\\t {}\".format(nib.__version__))\n",
    "from nibabel.testing import data_path\n",
    "import pandas as pd;             print(\"Pandas\\t\\t {}\".format(pd.__version__))\n",
    "import imageio;                  print(\"imageio\\t\\t {}\".format(imageio.__version__))\n",
    "import h5py;                     print(\"H5py\\t\\t {}\".format(h5py.__version__))\n",
    "import sklearn;                  print(\"Scikit-learn\\t {}\".format(sklearn.__version__))\n",
    "import skimage;                  print(\"Scikit-image\\t {}\".format(skimage.__version__))\n",
    "import tensorflow as tf;         print(\"TensorFlow\\t {}\".format(tf.__version__))\n",
    "import keras;                    print(\"Keras\\t\\t {}\".format(keras.__version__))\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import models, Input, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, BatchNormalization, Conv3D, MaxPooling3D, UpSampling3D, ZeroPadding3D\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "from sklearn.cluster import KMeans\n",
    "# %load_ext tensorboard       \n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape is (100, 182, 218, 182, 1)\n",
      "valid_data shape is (24, 182, 218, 182, 1)\n"
     ]
    }
   ],
   "source": [
    "## Load train data\n",
    "data_source = \"Data/data_random_1/\" \n",
    "sample_train_subset = np.loadtxt(os.path.join(data_source, \"sample_train.csv\"), dtype=str, delimiter=\",\")\n",
    "train_data = np.load(os.path.join(data_source, \"train.npy\")).reshape(100,182,218,182,1)\n",
    "print('train_data shape is {}'.format(train_data.shape))\n",
    "\n",
    "## Load validation data\n",
    "sample_val_subset = np.loadtxt(os.path.join(data_source, \"sample_valid.csv\"), dtype=str, delimiter=\",\")\n",
    "valid_data = np.load(os.path.join(data_source, \"valid.npy\")).reshape(24,182,218,182,1)\n",
    "print('valid_data shape is {}'.format(valid_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_padded_data shape is (100, 192, 256, 192, 1)\n",
      "valid_padded_data shape is (24, 192, 256, 192, 1)\n"
     ]
    }
   ],
   "source": [
    "## Padding datasets\n",
    "train_pad_data = (ZeroPadding3D(padding=(5,19,5))(train_data)).numpy()\n",
    "print('train_padded_data shape is {}'.format(train_pad_data.shape))\n",
    "\n",
    "valid_pad_data = (ZeroPadding3D(padding=(5,19,5))(valid_data)).numpy()\n",
    "print('valid_padded_data shape is {}'.format(valid_pad_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded data shape: [1, 192, 256, 192, 1]\n",
      "\n",
      "Model: \"AutoEncoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 192, 256, 192, 1) 0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv3D)               (None, 96, 128, 96, 128)  3584      \n",
      "_________________________________________________________________\n",
      "BN_Conv1 (BatchNormalization (None, 96, 128, 96, 128)  512       \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv3D)               (None, 48, 64, 48, 64)    221248    \n",
      "_________________________________________________________________\n",
      "BN_Conv2 (BatchNormalization (None, 48, 64, 48, 64)    256       \n",
      "_________________________________________________________________\n",
      "Conv3 (Conv3D)               (None, 24, 32, 24, 32)    55328     \n",
      "_________________________________________________________________\n",
      "BN_Conv3 (BatchNormalization (None, 24, 32, 24, 32)    128       \n",
      "_________________________________________________________________\n",
      "Conv4 (Conv3D)               (None, 12, 16, 12, 16)    13840     \n",
      "_________________________________________________________________\n",
      "BN_Conv4 (BatchNormalization (None, 12, 16, 12, 16)    64        \n",
      "_________________________________________________________________\n",
      "Conv5 (Conv3D)               (None, 6, 8, 6, 8)        3464      \n",
      "_________________________________________________________________\n",
      "BN_Conv5 (BatchNormalization (None, 6, 8, 6, 8)        32        \n",
      "_________________________________________________________________\n",
      "LF (Flatten)                 (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "encoded (Dense)              (None, 100)               230500    \n",
      "_________________________________________________________________\n",
      "BN_Dense (BatchNormalization (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2304)              232704    \n",
      "_________________________________________________________________\n",
      "UnFlat (Reshape)             (None, 6, 8, 6, 8)        0         \n",
      "_________________________________________________________________\n",
      "DeConv2 (Conv3D)             (None, 6, 8, 6, 8)        1736      \n",
      "_________________________________________________________________\n",
      "BN_DeConv2 (BatchNormalizati (None, 6, 8, 6, 8)        32        \n",
      "_________________________________________________________________\n",
      "UpSampling2 (UpSampling3D)   (None, 12, 16, 12, 8)     0         \n",
      "_________________________________________________________________\n",
      "DeConv3 (Conv3D)             (None, 12, 16, 12, 16)    3472      \n",
      "_________________________________________________________________\n",
      "BN_DeConv3 (BatchNormalizati (None, 12, 16, 12, 16)    64        \n",
      "_________________________________________________________________\n",
      "UpSampling3 (UpSampling3D)   (None, 24, 32, 24, 16)    0         \n",
      "_________________________________________________________________\n",
      "DeConv4 (Conv3D)             (None, 24, 32, 24, 32)    13856     \n",
      "_________________________________________________________________\n",
      "BN_DeConv4 (BatchNormalizati (None, 24, 32, 24, 32)    128       \n",
      "_________________________________________________________________\n",
      "UpSampling4 (UpSampling3D)   (None, 48, 64, 48, 32)    0         \n",
      "_________________________________________________________________\n",
      "DeConv5 (Conv3D)             (None, 48, 64, 48, 64)    55360     \n",
      "_________________________________________________________________\n",
      "BN_DeConv5 (BatchNormalizati (None, 48, 64, 48, 64)    256       \n",
      "_________________________________________________________________\n",
      "UpSampling5 (UpSampling3D)   (None, 96, 128, 96, 64)   0         \n",
      "_________________________________________________________________\n",
      "DeConv6 (Conv3D)             (None, 96, 128, 96, 128)  221312    \n",
      "_________________________________________________________________\n",
      "BN_DeConv6 (BatchNormalizati (None, 96, 128, 96, 128)  512       \n",
      "_________________________________________________________________\n",
      "UpSampling6 (UpSampling3D)   (None, 192, 256, 192, 128 0         \n",
      "_________________________________________________________________\n",
      "Output (Conv3D)              (None, 192, 256, 192, 1)  3457      \n",
      "=================================================================\n",
      "Total params: 1,062,245\n",
      "Trainable params: 1,061,053\n",
      "Non-trainable params: 1,192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Convolutional AutoEncoder Model Designe:\n",
    "\n",
    "IMAGE_HEIGHT = train_pad_data.shape[1]\n",
    "IMAGE_WIDTH = train_pad_data.shape[2]\n",
    "IMAGE_DEPTH = train_pad_data.shape[3]\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 1\n",
    "data_shape = [1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, 1]\n",
    "input_shape = [BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, 1]\n",
    "print(\"Padded data shape: {}\\n\".format(input_shape))\n",
    "\n",
    "## Encoder\n",
    "input_img = Input(shape=(192, 256, 192, 1), name='Input')\n",
    "x = Conv3D(filters=128, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv1')(input_img)\n",
    "x = BatchNormalization(name='BN_Conv1')(x)\n",
    "x = Conv3D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv2')(x)\n",
    "x = BatchNormalization(name='BN_Conv2')(x)\n",
    "x = Conv3D(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv3')(x)\n",
    "x = BatchNormalization(name='BN_Conv3')(x)\n",
    "x = Conv3D(filters=16, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv4')(x)\n",
    "x = BatchNormalization(name='BN_Conv4')(x)\n",
    "x = Conv3D(filters=8, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv5')(x)\n",
    "x = BatchNormalization(name='BN_Conv5')(x)\n",
    "\n",
    "## Latent Features\n",
    "shape_before_flattening = tf.keras.backend.int_shape(x)\n",
    "x_LF = Flatten(name='LF')(x)\n",
    "\n",
    "##____________________________________________________________________________________________________\n",
    "# init = VarianceScaling(scale=1. / 3., mode='fan_in', distribution='uniform')\n",
    "# encoded = Dense(50, kernel_initializer=init, activation='relu', name='encoded')(x_LF)\n",
    "x_LF = Dense(100, activation='relu', name='encoded')(x_LF)\n",
    "##____________________________________________________________________________________________________\n",
    "\n",
    "encoded = x_LF    # Hadi for L200\n",
    "\n",
    "##____________________________________________________________________________________________________\n",
    "x = BatchNormalization(name='BN_Dense')(encoded)\n",
    "# x = Dense(np.prod(shape_before_flattening[1:]), activation='relu', kernel_initializer=init)(encoded)\n",
    "x = Dense(np.prod(shape_before_flattening[1:]), activation='relu')(x)\n",
    "encoded = x\n",
    "##____________________________________________________________________________________________________\n",
    "\n",
    "x = Reshape(shape_before_flattening[1:], name='UnFlat')(encoded)\n",
    "\n",
    "## Decoder\n",
    "x = Conv3D(filters=8, kernel_size=3, padding='same', activation='relu', name='DeConv2')(x)\n",
    "x = BatchNormalization(name='BN_DeConv2')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling2')(x)\n",
    "x = Conv3D(filters=16, kernel_size=3, padding='same', activation='relu', name='DeConv3')(x)\n",
    "x = BatchNormalization(name='BN_DeConv3')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling3')(x)\n",
    "x = Conv3D(filters=32, kernel_size=3, padding='same', activation='relu', name='DeConv4')(x)\n",
    "x = BatchNormalization(name='BN_DeConv4')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling4')(x)\n",
    "x = Conv3D(filters=64, kernel_size=3, padding='same', activation='relu', name='DeConv5')(x)\n",
    "x = BatchNormalization(name='BN_DeConv5')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling5')(x)\n",
    "x = Conv3D(filters=128, kernel_size=3, padding='same', activation='relu', name='DeConv6')(x)\n",
    "x = BatchNormalization(name='BN_DeConv6')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling6')(x)\n",
    "decoded = Conv3D(filters=1, kernel_size=3, padding='same', activation='sigmoid', name='Output')(x)\n",
    "\n",
    "model_CAE = Model(inputs=input_img, outputs=decoded, name='AutoEncoder')\n",
    "## optimizer=rmsprop, sgd\n",
    "model_CAE.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model_CAE.summary()\n",
    "# plot_model(model_CAE, to_file='Convolutional_autoencoder_model.png', show_shapes=True)\n",
    "# Image(filename='Convolutional_autoencoder_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start Time = 2021_01_04___08_40 \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer AutoEncoder: expected shape=(None, 192, 256, 192, 1), found shape=(1, 182, 218, 182, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-020f4c1d633c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=5, mode='auto')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# model_CAE.fit(train_data[0:10,:], train_data[0:10,:], validation_data=(valid_data, valid_data), epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True, callbacks=[tb_callback, model_checkpoint_callback], verbose=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel_CAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mmodel_CAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Weights/P5_100___\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/shossein/anaconda3/envs/m36/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer AutoEncoder: expected shape=(None, 192, 256, 192, 1), found shape=(1, 182, 218, 182, 1)\n"
     ]
    }
   ],
   "source": [
    "## Start time:\n",
    "from datetime import datetime\n",
    "start_time = datetime.now().strftime(\"%Y_%m_%d___%H_%M\"); print(\"\\nStart Time =\", start_time, \"\\n\")\n",
    "\n",
    "## Model Fit\n",
    "# model_CAE.load_weights(os.path.join(\"Weights/L1.hdf5\"), by_name=True)  # 1\n",
    "# model_CAE.load_weights(os.path.join(\"Weights/L200___2021_01_03___05_48.hdf5\"))  # 100\n",
    "# model_CAE.load_weights(os.path.join(\"Weights/L100___2021_01_01___23_57.hdf5\"), by_name=True)  # 500\n",
    "# model_CAE.load_weights(os.path.join(\"Weights/L100___2021_01_02___08_37.hdf5\"), by_name=True)  # 1000\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath=os.path.join(\"Check/P5_100___\" + start_time), save_weights_only=True, save_best_only=True, monitor='val_loss', mode='max', verbose=1) \n",
    "tb_callback = TensorBoard(os.path.join(\"Logs/P5_100___\" + start_time), histogram_freq=1)\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=5, mode='auto')\n",
    "# model_CAE.fit(train_data[0:10,:], train_data[0:10,:], validation_data=(valid_data, valid_data), epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True, callbacks=[tb_callback, model_checkpoint_callback], verbose=1)\n",
    "model_CAE.fit(train_data, train_data, validation_data=(valid_data, valid_data), epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True, callbacks=[tb_callback, model_checkpoint_callback], verbose=1)\n",
    "model_CAE.save_weights(os.path.join(\"Weights/P5_100___\" + start_time + \".hdf5\"))\n",
    "\n",
    "## End time:\n",
    "from datetime import datetime\n",
    "end_time = datetime.now().strftime(\"%Y_%m_%d___%H_%M\"); print(\"\\nEnd Time =\", end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reconstructing data \n",
    "\n",
    "test_pad_data = train_pad_data[0,:].reshape(1, 192, 256, 192, 1)\n",
    "reconstructed = model_CAE.predict(test_pad_data)\n",
    "\n",
    "# for m in range(1):\n",
    "#     slice_0 = test_pad_data[m, 96, :, :, 0]\n",
    "#     slice_1 = test_pad_data[m, :, 128, :, 0]\n",
    "#     slice_2 = test_pad_data[m, :, :, 96, 0]\n",
    "#     show_slices([slice_0, slice_1, slice_2])\n",
    "#     plt.suptitle(sample_train_subset[m], x=0.5, y=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\ntrain_pad_data[0,100,100:105,100]\\n\\n {}'.format(train_pad_data[0,100,100:105,100]),'\\n')\n",
    "print('\\nReconstructed_data[0,100,100:105,100]\\n\\n {}'.format(reconstructed[0,100,100:105,100]),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Encoder = Model(inputs=input_img, outputs=encoded, name='Encoder')\n",
    "model_Encoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "# model_Encoder.summary()\n",
    "# plot_model(model_Encoder, to_file='Encoder_model.png', show_shapes=True)\n",
    "# Image(filename='Encoder_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pad_data = train_pad_data[0,:].reshape(1, 192, 256, 192, 1)\n",
    "LF_features = model_Encoder.predict(test_pad_data)[0]\n",
    "\n",
    "print('LF_features size: {} -------- {} \\n'.format(LF_features.shape, type(LF_features)))\n",
    "print('The first feature is {}\\n'.format(LF_features[0]))\n",
    "print(LF_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
