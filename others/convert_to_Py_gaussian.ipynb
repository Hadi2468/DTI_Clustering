{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nVersion control:\\n\")\n",
    "import os     # operating system interfaces\n",
    "import fnmatch\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np; print(\"Numpy\\t\\t\", np.__version__)\n",
    "import matplotlib as mpl; print(\"matplotlib\\t\", mpl.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib; print(\"NiBabel\\t\\t\", nib.__version__)\n",
    "from nibabel.testing import data_path\n",
    "import math\n",
    "import pandas as pd; print(\"Pandas\\t\\t\", pd.__version__)\n",
    "import sys\n",
    "import imageio; print(\"imageio\\t\\t\", imageio.__version__)\n",
    "import h5py; print(\"H5py\\t\\t\", h5py.__version__)\n",
    "import sklearn; print(\"Scikit-learn\\t\", sklearn.__version__)\n",
    "import skimage; print(\"Scikit-image\\t\", skimage.__version__)\n",
    "import tensorflow as tf; print(\"TensorFlow\\t\", tf.__version__)\n",
    "import keras; print(\"Keras\\t\\t\", keras.__version__)\n",
    "from tensorflow.keras import models, Input, Model\n",
    "from tensorflow.keras.layers import Dense, Conv3D, Conv3DTranspose, MaxPooling3D, UpSampling3D\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loaded = np.random.normal(0.5, 0.05, (5, 182, 218, 182)).reshape((5, 182, 218, 182, 1))\n",
    "valid_data_loaded = np.random.normal(0.5, 0.05, (3, 182, 218, 182)).reshape((3, 182, 218, 182, 1))\n",
    "arr0 = np.min(train_data_loaded)\n",
    "arr1 = np.max(train_data_loaded)\n",
    "arr2 = np.min(valid_data_loaded)\n",
    "arr3 = np.max(valid_data_loaded)\n",
    "print('\\nShape of Train and Valid datasets are', train_data_loaded.shape, valid_data_loaded.shape)\n",
    "print('Minimum and Maximum value of Train and Valid datasets are', arr0, arr1, arr2, arr3)\n",
    "print('element of [1, 100, 100 ,100, 1] is', train_data_loaded[[1],[100],[100],[100]], valid_data_loaded[[1],[100],[100],[100]], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define parameters:\n",
    "\n",
    "IMAGE_HEIGHT = train_data_loaded.shape[1]\n",
    "IMAGE_WIDTH = train_data_loaded.shape[2]\n",
    "IMAGE_DEPTH = train_data_loaded.shape[3]\n",
    "batch_size = 32\n",
    "data_shape = [1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, 1]\n",
    "input_shape = [batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, 1]\n",
    "# print(\"input-layer shape:\", input_shape)\n",
    "\n",
    "## Encoder\n",
    "input_img = Input(shape=(182, 218, 182, 1))\n",
    "x = Conv3D(filters=16, kernel_size=(3, 3, 3), padding='same', activation='relu', name='Conv1')(input_img)\n",
    "x = MaxPooling3D(pool_size=(13, 13, 13), padding='same')(x)\n",
    "x = Conv3D(filters=8, kernel_size=(3, 3, 3), padding='same', activation='relu', name='Conv2')(x)\n",
    "encoded = MaxPooling3D(pool_size=(7, 7, 7), padding='same')(x)\n",
    "## at this point the representation is (2, 3, 2, 8) i.e. 96-dimensional instead of 7,221,032\n",
    "\n",
    "## Decoder\n",
    "x = Conv3DTranspose(filters=4, kernel_size=(3, 3, 3), padding='same', activation='relu', name='DeConv3')(encoded)\n",
    "x = UpSampling3D(size=(7, 6, 7))(x)\n",
    "x = Conv3DTranspose(filters=8, kernel_size=(3, 3, 3), padding='same', activation='relu', name='DeConv4')(x)\n",
    "x = UpSampling3D(size=(13, 12, 13))(x)\n",
    "decoded = Conv3DTranspose(filters=1, kernel_size=(1, 3, 1), padding='valid', activation='sigmoid', name='DeConv5')(x)\n",
    "\n",
    "autoencoder = Model(inputs=input_img, outputs=decoded)\n",
    "autoencoder.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "# autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(train_data_loaded, train_data_loaded, epochs=3, batch_size=batch_size, shuffle=True, validation_data=(valid_data_loaded, valid_data_loaded), verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
