{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"    Version control\\n------------------------\")\n",
    "import os, fnmatch, random, math, sys, datetime\n",
    "from pathlib import Path\n",
    "import numpy as np;              print(\"Numpy\\t\\t\", np.__version__)\n",
    "import matplotlib as mpl;        print(\"matplotlib\\t\", mpl.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib;           print(\"NiBabel\\t\\t {}\".format(nib.__version__))\n",
    "from nibabel.testing import data_path\n",
    "import pandas as pd;             print(\"Pandas\\t\\t {}\".format(pd.__version__))\n",
    "import imageio;                  print(\"imageio\\t\\t {}\".format(imageio.__version__))\n",
    "import h5py;                     print(\"H5py\\t\\t {}\".format(h5py.__version__))\n",
    "import sklearn;                  print(\"Scikit-learn\\t {}\".format(sklearn.__version__))\n",
    "import skimage;                  print(\"Scikit-image\\t {}\".format(skimage.__version__))\n",
    "import tensorflow as tf;         print(\"TensorFlow\\t {}\".format(tf.__version__))\n",
    "import keras;                    print(\"Keras\\t\\t {}\".format(keras.__version__))\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import models, Input, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, BatchNormalization, Conv3D, MaxPooling3D, UpSampling3D, ZeroPadding3D\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "from sklearn.cluster import KMeans\n",
    "# %load_ext tensorboard       \n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load train data\n",
    "data_source = \"Data/data_random_1/\" \n",
    "sample_train_subset = np.loadtxt(os.path.join(data_source, \"sample_train.csv\"), dtype=str, delimiter=\",\")\n",
    "train_data = np.load(os.path.join(data_source, \"train.npy\")).reshape(100,182,218,182,1)\n",
    "print('train_data shape is {}'.format(train_data.shape))\n",
    "\n",
    "## Load validation data\n",
    "sample_val_subset = np.loadtxt(os.path.join(data_source, \"sample_valid.csv\"), dtype=str, delimiter=\",\")\n",
    "valid_data = np.load(os.path.join(data_source, \"valid.npy\")).reshape(24,182,218,182,1)\n",
    "print('valid_data shape is {}'.format(valid_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Padding datasets\n",
    "train_pad_data = (ZeroPadding3D(padding=(5,19,5))(train_data)).numpy()\n",
    "print('train_padded_data shape is {}'.format(train_pad_data.shape))\n",
    "\n",
    "valid_pad_data = (ZeroPadding3D(padding=(5,19,5))(valid_data)).numpy()\n",
    "print('valid_padded_data shape is {}'.format(valid_pad_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convolutional AutoEncoder Model Designe:\n",
    "\n",
    "IMAGE_HEIGHT = train_pad_data.shape[1]\n",
    "IMAGE_WIDTH = train_pad_data.shape[2]\n",
    "IMAGE_DEPTH = train_pad_data.shape[3]\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 1\n",
    "data_shape = [1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, 1]\n",
    "input_shape = [BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH, 1]\n",
    "print(\"Padded data shape: {}\\n\".format(input_shape))\n",
    "\n",
    "## Encoder\n",
    "input_img = Input(shape=(192, 256, 192, 1), name='Input')\n",
    "x = Conv3D(filters=128, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv1')(input_img)\n",
    "x = BatchNormalization(name='BN_Conv1')(x)\n",
    "x = Conv3D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv2')(x)\n",
    "x = BatchNormalization(name='BN_Conv2')(x)\n",
    "x = Conv3D(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv3')(x)\n",
    "x = BatchNormalization(name='BN_Conv3')(x)\n",
    "x = Conv3D(filters=16, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv4')(x)\n",
    "x = BatchNormalization(name='BN_Conv4')(x)\n",
    "x = Conv3D(filters=8, kernel_size=3, strides=2, padding='same', activation='relu', name='Conv5')(x)\n",
    "x = BatchNormalization(name='BN_Conv5')(x)\n",
    "\n",
    "## Latent Features\n",
    "shape_before_flattening = tf.keras.backend.int_shape(x)\n",
    "x_LF = Flatten(name='LF')(x)\n",
    "\n",
    "##____________________________________________________________________________________________________\n",
    "# init = VarianceScaling(scale=1. / 3., mode='fan_in', distribution='uniform')\n",
    "# encoded = Dense(50, kernel_initializer=init, activation='relu', name='encoded')(x_LF)\n",
    "# x_LF = Dense(100, activation='relu', name='encoded')(x_LF)\n",
    "##____________________________________________________________________________________________________\n",
    "\n",
    "encoded = x_LF    # Hadi for L200\n",
    "\n",
    "##____________________________________________________________________________________________________\n",
    "# x = BatchNormalization(name='BN_Dense')(encoded)\n",
    "# # x = Dense(np.prod(shape_before_flattening[1:]), activation='relu', kernel_initializer=init)(encoded)\n",
    "# x = Dense(np.prod(shape_before_flattening[1:]), activation='relu')(x)\n",
    "# encoded = x\n",
    "##____________________________________________________________________________________________________\n",
    "\n",
    "x = Reshape(shape_before_flattening[1:], name='UnFlat')(encoded)\n",
    "\n",
    "## Decoder\n",
    "x = Conv3D(filters=8, kernel_size=3, padding='same', activation='relu', name='DeConv2')(x)\n",
    "x = BatchNormalization(name='BN_DeConv2')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling2')(x)\n",
    "x = Conv3D(filters=16, kernel_size=3, padding='same', activation='relu', name='DeConv3')(x)\n",
    "x = BatchNormalization(name='BN_DeConv3')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling3')(x)\n",
    "x = Conv3D(filters=32, kernel_size=3, padding='same', activation='relu', name='DeConv4')(x)\n",
    "x = BatchNormalization(name='BN_DeConv4')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling4')(x)\n",
    "x = Conv3D(filters=64, kernel_size=3, padding='same', activation='relu', name='DeConv5')(x)\n",
    "x = BatchNormalization(name='BN_DeConv5')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling5')(x)\n",
    "x = Conv3D(filters=128, kernel_size=3, padding='same', activation='relu', name='DeConv6')(x)\n",
    "x = BatchNormalization(name='BN_DeConv6')(x)\n",
    "x = UpSampling3D(size=(2, 2, 2), name='UpSampling6')(x)\n",
    "decoded = Conv3D(filters=1, kernel_size=3, padding='same', activation='sigmoid', name='Output')(x)\n",
    "\n",
    "model_CAE = Model(inputs=input_img, outputs=decoded, name='AutoEncoder')\n",
    "## optimizer=rmsprop, sgd\n",
    "model_CAE.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model_CAE.summary()\n",
    "# plot_model(model_CAE, to_file='Convolutional_autoencoder_model.png', show_shapes=True)\n",
    "# Image(filename='Convolutional_autoencoder_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start time:\n",
    "from datetime import datetime\n",
    "start_time = datetime.now().strftime(\"%Y_%m_%d___%H_%M\"); print(\"\\nStart Time =\", start_time, \"\\n\")\n",
    "\n",
    "## Model Fit\n",
    "# model_CAE.load_weights(os.path.join(\"Weights/L1.hdf5\"), by_name=True)  # 1\n",
    "# model_CAE.load_weights(os.path.join(\"Weights/L200___2021_01_03___05_48.hdf5\"))  # 100\n",
    "# model_CAE.load_weights(os.path.join(\"Weights/L100___2021_01_01___23_57.hdf5\"), by_name=True)  # 500\n",
    "# model_CAE.load_weights(os.path.join(\"Weights/L100___2021_01_02___08_37.hdf5\"), by_name=True)  # 1000\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath=os.path.join(\"Check/P5_2304___\" + start_time), save_weights_only=True, save_best_only=True, monitor='val_loss', mode='max', verbose=1) \n",
    "tb_callback = TensorBoard(os.path.join(\"Logs/P5_2304___\" + start_time), histogram_freq=1)\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=5, mode='auto')\n",
    "# model_CAE.fit(train_data[0:10,:], train_data[0:10,:], validation_data=(valid_data, valid_data), epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True, callbacks=[tb_callback, model_checkpoint_callback], verbose=1)\n",
    "model_CAE.fit(train_data, train_data, validation_data=(valid_data, valid_data), epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True, callbacks=[tb_callback, model_checkpoint_callback], verbose=1)\n",
    "model_CAE.save_weights(os.path.join(\"Weights/P5_2304___\" + start_time + \".hdf5\"))\n",
    "\n",
    "## End time:\n",
    "from datetime import datetime\n",
    "end_time = datetime.now().strftime(\"%Y_%m_%d___%H_%M\"); print(\"\\nEnd Time =\", end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reconstructing data \n",
    "\n",
    "test_pad_data = train_pad_data[0,:].reshape(1, 192, 256, 192, 1)\n",
    "reconstructed = model_CAE.predict(test_pad_data)\n",
    "\n",
    "# for m in range(1):\n",
    "#     slice_0 = test_pad_data[m, 96, :, :, 0]\n",
    "#     slice_1 = test_pad_data[m, :, 128, :, 0]\n",
    "#     slice_2 = test_pad_data[m, :, :, 96, 0]\n",
    "#     show_slices([slice_0, slice_1, slice_2])\n",
    "#     plt.suptitle(sample_train_subset[m], x=0.5, y=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\ntrain_pad_data[0,100,100:105,100]\\n\\n {}'.format(train_pad_data[0,100,100:105,100]),'\\n')\n",
    "print('\\nReconstructed_data[0,100,100:105,100]\\n\\n {}'.format(reconstructed[0,100,100:105,100]),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Encoder = Model(inputs=input_img, outputs=encoded, name='Encoder')\n",
    "model_Encoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "# model_Encoder.summary()\n",
    "# plot_model(model_Encoder, to_file='Encoder_model.png', show_shapes=True)\n",
    "# Image(filename='Encoder_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pad_data = train_pad_data[0,:].reshape(1, 192, 256, 192, 1)\n",
    "LF_features = model_Encoder.predict(test_pad_data)[0]\n",
    "\n",
    "print('LF_features size: {} -------- {} \\n'.format(LF_features.shape, type(LF_features)))\n",
    "print('The first feature is {}\\n'.format(LF_features[0]))\n",
    "print(LF_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
